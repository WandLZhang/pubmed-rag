{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header-markdown"
      },
      "source": [
        "# PubMed Medical Literature Analysis with Gradio\n",
        "\n",
        "<table style=\"float: left; margin-right: 20px;\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Gradio.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Gradio.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "## 🚀 Quick Start\n",
        "\n",
        "1. Click **Runtime → Run all** (or press Ctrl/Cmd + F9)\n",
        "2. Wait for the app to launch (~30 seconds)\n",
        "3. Click the Gradio link that appears\n",
        "\n",
        "This notebook analyzes medical cases using PubMed literature with BigQuery vector search and Gemini AI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install-dependencies",
        "cellView": "form"
      },
      "source": [
        "# @title 1️⃣ Install Dependencies { display-mode: \"form\" }\n",
        "!pip install gradio google-genai google-cloud-bigquery pandas plotly -q\n",
        "print(\"✅ Dependencies installed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "authentication",
        "cellView": "form"
      },
      "source": [
        "# @title 2️⃣ Authenticate with Google Cloud { display-mode: \"form\" }\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    print(\"✅ Authenticated with Google Cloud\")\n",
        "else:\n",
        "    print(\"ℹ️ Running locally - using default credentials\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "configuration",
        "cellView": "form"
      },
      "source": [
        "# @title 3️⃣ Configuration { display-mode: \"form\" }\n",
        "import os\n",
        "\n",
        "# User configuration\n",
        "PROJECT_ID = \"\" # @param {type:\"string\"}\n",
        "if not PROJECT_ID:\n",
        "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"\")\n",
        "\n",
        "LOCATION = \"us-central1\" # @param [\"us-central1\", \"us-east1\", \"us-west1\", \"europe-west1\", \"asia-northeast1\"] {type:\"string\"}\n",
        "USER_DATASET = \"pubmed\" # @param {type:\"string\"}\n",
        "\n",
        "# Constants\n",
        "PUBMED_DATASET = \"wz-data-catalog-demo.pubmed\"\n",
        "PUBMED_TABLE = f\"{PUBMED_DATASET}.pmid_embed_nonzero_metadata\"\n",
        "EMBEDDING_MODEL = f\"{PROJECT_ID}.{USER_DATASET}.textembed\"\n",
        "MODEL_ID = \"gemini-2.5-flash\"\n",
        "JOURNAL_IMPACT_CSV_URL = \"https://raw.githubusercontent.com/WandLZhang/scimagojr_2024/main/scimagojr_2024.csv\"\n",
        "\n",
        "# Sample case for demo\n",
        "SAMPLE_CASE = \"\"\"A 4-year-old male presents with a 3-week history of progressive fatigue, pallor, and easy bruising. \\n",
        "Physical examination reveals hepatosplenomegaly and scattered petechiae. \\n",
        "\\n",
        "Laboratory findings:\\n",
        "- WBC: 45,000/μL with 80% blasts\\n",
        "- Hemoglobin: 7.2 g/dL\\n",
        "- Platelets: 32,000/μL\\n",
        "\\n",
        "Flow cytometry: CD33+, CD13+, CD117+, CD34+, HLA-DR+, CD19-, CD3-\\n",
        "\\n",
        "Cytogenetics: 46,XY,t(9;11)(p21.3;q23.3)\\n",
        "Molecular: KMT2A-MLLT3 fusion detected, FLT3-ITD positive, NRAS G12D mutation\\n",
        "\\n",
        "Diagnosis: KMT2A-rearranged acute myeloid leukemia (AML)\"\"\"\n",
        "\n",
        "print(f\"📍 Project: {PROJECT_ID}\")\n",
        "print(f\"📍 Location: {LOCATION}\")\n",
        "print(f\"📍 Dataset: {USER_DATASET}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "all-in-one-app"
      },
      "source": [
        "# @title 4️⃣ Launch PubMed Analysis App { display-mode: \"form\" }\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from google import genai\n",
        "from google.cloud import bigquery\n",
        "from google.genai.types import GenerateContentConfig\n",
        "\n",
        "# --- Global Variables ---\n",
        "genai_client, bq_client = None, None\n",
        "journal_impact_dict = {}\n",
        "\n",
        "# --- Core Functions ---\n",
        "def init_clients(project_id, location):\n",
        "    try:\n",
        "        genai_client = genai.Client(vertexai=True, project=project_id, location=location)\n",
        "        bq_client = bigquery.Client(project=project_id)\n",
        "        return genai_client, bq_client\n",
        "    except Exception as e:\n",
        "        return None, None\n",
        "\n",
        "def load_journal_data():\n",
        "    try:\n",
        "        df = pd.read_csv(JOURNAL_IMPACT_CSV_URL, sep=';')\n",
        "        return dict(zip(df['Title'], df['SJR']))\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def extract_medical_info(case_text, client):\n",
        "    prompts = {\n",
        "        \"disease\": \"Extract the primary disease diagnosis. Return ONLY the name.\",\n",
        "        \"events\": \"Extract all actionable medical events (mutations, biomarkers, etc.). Return a comma-separated list.\"\n",
        "    }\n",
        "    results = {}\n",
        "    for key, prompt in prompts.items():\n",
        "        full_prompt = f\"{prompt}\\n\\nCase notes:\\n{case_text}\"\n",
        "        response = client.models.generate_content(model=MODEL_ID, contents=[full_prompt], config=GenerateContentConfig(temperature=0))\n",
        "        results[key] = response.text.strip()\n",
        "    return results\n",
        "\n",
        "def search_pubmed_articles(disease, events, bq_client, embedding_model, pubmed_table, top_k):\n",
        "    query_text = f\"{disease} {' '.join(events)}\"\n",
        "    sql = f\"\"\"SELECT base.PMID, base.content, base.text as abstract, distance FROM VECTOR_SEARCH(TABLE `{pubmed_table}`, 'ml_generate_embedding_result', (SELECT ml_generate_embedding_result FROM ML.GENERATE_EMBEDDING(MODEL `{embedding_model}`, (SELECT \\\"{query_text}\\\" AS content))), top_k => {top_k})\"\"\"\n",
        "    return bq_client.query(sql).to_dataframe()\n",
        "\n",
        "def analyze_article_batch(df, disease, events, client, journal_dict):\n",
        "    journal_context = \"\\n\".join([f\"- {title}: {sjr}\" for title, sjr in journal_dict.items()])\n",
        "    prompt = f\"\"\"Analyze articles for relevance to Disease: {disease} and Events: {', '.join(events)}. Use this data: {journal_context}. For each, extract: title, journal_title, journal_sjr, year, disease_match (bool), pediatric_focus (bool), treatment_shown (bool), paper_type, key_findings, clinical_trial (bool), novel_findings (bool). Return JSON array.\"\"\"\n",
        "    articles_text = \"\"\n",
        "    for _, row in df.iterrows():\n",
        "        content = row.get('content', row.get('abstract', ''))\n",
        "        articles_text += f\"\\n---\\nPMID: {row['PMID']}\\nContent: {content}\\n\"\n",
        "    response = client.models.generate_content(model=MODEL_ID, contents=[prompt + articles_text], config=GenerateContentConfig(temperature=0, response_mime_type=\"application/json\"))\n",
        "    try:\n",
        "        return json.loads(response.text)\n",
        "    except json.JSONDecodeError:\n",
        "        return []\n",
        "\n",
        "def calculate_article_score(metadata, config):\n",
        "    score = 0\n",
        "    # Simplified scoring logic for brevity\n",
        "    if metadata.get('disease_match'): score += config.get('disease_match', 50)\n",
        "    if metadata.get('treatment_shown'): score += config.get('treatment_efficacy', 50)\n",
        "    if metadata.get('clinical_trial'): score += config.get('clinical_trial', 40)\n",
        "    return round(score, 2)\n",
        "\n",
        "def setup_bigquery(project, dataset, location, client):\n",
        "    try:\n",
        "        client.get_dataset(f\"{project}.{dataset}\")\n",
        "    except:\n",
        "        client.create_dataset(bigquery.Dataset(f\"{project}.{dataset}\"), exists_ok=True)\n",
        "    model_query = f\"CREATE MODEL IF NOT EXISTS `{project}.{dataset}.textembed` REMOTE WITH CONNECTION DEFAULT OPTIONS(endpoint='text-embedding-005');\"\n",
        "    client.query(model_query).result()\n",
        "    return f\"✅ BigQuery setup complete for {project}.{dataset}\"\n",
        "\n",
        "# --- Gradio App Logic ---\n",
        "def validate_project_and_setup(project_id, dataset_name):\n",
        "    global genai_client, bq_client, journal_impact_dict, PROJECT_ID, USER_DATASET\n",
        "    if not project_id or not dataset_name:\n",
        "        return \"❌ Project ID and Dataset Name are required.\", gr.update(interactive=False)\n",
        "    PROJECT_ID = project_id\n",
        "    USER_DATASET = dataset_name\n",
        "    genai_client, bq_client = init_clients(project_id, LOCATION)\n",
        "    if not genai_client or not bq_client:\n",
        "        return \"❌ Failed to initialize clients. Check permissions.\", gr.update(interactive=False)\n",
        "    journal_impact_dict = load_journal_data()\n",
        "    setup_message = setup_bigquery(project_id, dataset_name, LOCATION, bq_client)\n",
        "    return f\"✅ Project validated. Loaded {len(journal_impact_dict)} journals.\\n{setup_message}\", gr.update(interactive=True)\n",
        "\n",
        "def run_analysis(case_text, num_articles, progress=gr.Progress()):\n",
        "    if not genai_client or not bq_client:\n",
        "        return None, \"❌ Please validate project first.\", {}\n",
        "    progress(0.1, desc=\"Extracting medical info...\")\n",
        "    medical_info = extract_medical_info(case_text, genai_client)\n",
        "    disease = medical_info.get('disease', '')\n",
        "    events = [e.strip() for e in medical_info.get('events', '').split(',')]\n",
        "    \n",
        "    progress(0.3, desc=\"Searching PubMed...\")\n",
        "    embedding_model_path = f\"{PROJECT_ID}.{USER_DATASET}.textembed\"\n",
        "    articles_df = search_pubmed_articles(disease, events, bq_client, embedding_model_path, PUBMED_TABLE, num_articles)\n",
        "    \n",
        "    progress(0.6, desc=\"Analyzing articles...\")\n",
        "    analyses = analyze_article_batch(articles_df, disease, events, genai_client, journal_impact_dict)\n",
        "    \n",
        "    # Merge and score\n",
        "    for i, analysis in enumerate(analyses):\n",
        "        for k, v in analysis.items():\n",
        "            articles_df.loc[i, k] = v\n",
        "    \n",
        "    scoring_config = SCORING_PRESETS[\"Clinical Focus\"] # Simplified for this version\n",
        "    articles_df['score'] = articles_df.apply(lambda row: calculate_article_score(row, scoring_config), axis=1)\n",
        "    articles_df = articles_df.sort_values('score', ascending=False).reset_index()\n",
        "    \n",
        "    progress(0.9, desc=\"Generating results...\")\n",
        "    results_table = articles_df[['score', 'title', 'journal_title', 'year']].head(10)\n",
        "    results = {'articles': articles_df.to_dict('records'), 'disease': disease, 'events': events, 'case_text': case_text}\n",
        "    return results_table, f\"✅ Analysis complete for '{disease}'.\", results\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🏥 PubMed Medical Literature Analysis\")\n",
        "    app_state = gr.State({})\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"1. Setup\"):\n",
        "            project_id_input = gr.Textbox(label=\"Google Cloud Project ID\", value=PROJECT_ID)\n",
        "            dataset_input = gr.Textbox(label=\"BigQuery Dataset Name\", value=USER_DATASET)\n",
        "            setup_btn = gr.Button(\"Validate & Setup Project\", variant=\"primary\")\n",
        "            setup_status = gr.Markdown()\n",
        "\n",
        "        with gr.TabItem(\"2. Analyze Case\"):\n",
        "            case_input = gr.Textbox(label=\"Patient Case Notes\", value=SAMPLE_CASE, lines=10)\n",
        "            num_articles_slider = gr.Slider(5, 50, 10, step=1, label=\"Number of Articles to Analyze\")\n",
        "            analyze_btn = gr.Button(\"Run Full Analysis\", variant=\"primary\", interactive=False)\n",
        "            analysis_status = gr.Markdown()\n",
        "\n",
        "        with gr.TabItem(\"3. Results\"):\n",
        "            results_df = gr.DataFrame(label=\"Top 10 Ranked Articles\")\n",
        "\n",
        "    setup_btn.click(validate_project_and_setup, inputs=[project_id_input, dataset_input], outputs=[setup_status, analyze_btn])\n",
        "    analyze_btn.click(run_analysis, inputs=[case_input, num_articles_slider], outputs=[results_df, analysis_status, app_state])\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
