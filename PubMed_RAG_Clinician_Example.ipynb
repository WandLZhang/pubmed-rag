{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "license-header"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header-markdown"
   },
   "source": [
    "# PubMed Medical Literature Analysis\n",
    "\n",
    "<table style=\"float: left; margin-right: 20px;\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FWandLZhang%2Fpubmed-rag%2Fmain%2FPubMed_RAG_Clinician_Example.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/WandLZhang/pubmed-rag/main/PubMed_RAG_Clinician_Example.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/WandLZhang/pubmed-rag/blob/main/PubMed_RAG_Clinician_Example.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>\n",
    "\n",
    "\n",
    "| Authors |\n",
    "| --- |\n",
    "| [Willis Zhang](https://github.com/WandLZhang) |\n",
    "| [Stone Jiang](https://github.com/siduojiang) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**Blog Post: Medical Literature Analysis with PubMed, BigQuery, Gemini**\n",
    "\n",
    "<a href=\"[blog-post-url-placeholder]\" target=\"_blank\">\n",
    "  <img src=\"https://storage.googleapis.com/[placeholder-image-path]/medical-literature-blog-header.jpg\" alt=\"Medical Literature Analysis with PubMed and Gemini\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "This notebook demonstrates how to analyze medical cases using PubMed literature with BigQuery vector search and Gemini. It converts the basic user experience from the [Capricorn Medical Research Application](https://capricorn-medical-research.web.app/) into an interactive Colab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-start"
   },
   "source": [
    "## üöÄ Quick Start\n",
    "\n",
    "1. Click **Runtime ‚Üí Run all** (or press Ctrl/Cmd + F9)\n",
    "2. Authenticate to your user account in the pop up\n",
    "3. Continue in the embedded Gradio app or click the link that appears\n",
    "\n",
    "This notebook analyzes medical cases using PubMed literature with BigQuery vector search and Gemini AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# @title 1Ô∏è‚É£ Install Dependencies { display-mode: \"form\" }\n",
    "!pip install gradio google-genai google-cloud-bigquery google-cloud-resource-manager google-cloud-service-usage pandas plotly google-cloud-billing -q\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "authentication"
   },
   "outputs": [],
   "source": [
    "# @title 2Ô∏è‚É£ Authenticate with Google Cloud { display-mode: \"form\" }\n",
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"‚úÖ Authenticated with Google Cloud\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Running locally - using default credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "all-in-one-app"
   },
   "outputs": [],
   "source": [
    "# @title 3Ô∏è‚É£ Launch PubMed Analysis App { display-mode: \"form\" }\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import resourcemanager_v3\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud import billing_v1\n",
    "from google.auth import default\n",
    "from google.genai.types import GenerateContentConfig\n",
    "import time\n",
    "import os\n",
    "import webbrowser\n",
    "import argparse\n",
    "\n",
    "# --- Global Credentials ---\n",
    "# We will capture credentials after authentication and pass them to all clients\n",
    "CREDENTIALS, _ = default()\n",
    "\n",
    "# --- Constants ---\n",
    "PUBMED_DATASET = \"wz-data-catalog-demo.pubmed\"\n",
    "PUBMED_TABLE = f\"{PUBMED_DATASET}.pmid_embed_nonzero_metadata\"\n",
    "MODEL_ID = \"gemini-1.5-flash\"  # Default model, will be updated dynamically\n",
    "THINKING_BUDGET = 0  # Default thinking budget, will be updated dynamically\n",
    "JOURNAL_IMPACT_CSV_URL = \"https://raw.githubusercontent.com/WandLZhang/scimagojr_2024/main/scimagojr_2024.csv\"\n",
    "REQUIRED_APIS = [\"aiplatform.googleapis.com\", \"bigquery.googleapis.com\", \"cloudresourcemanager.googleapis.com\"]\n",
    "CREATE_BILLING_ACCOUNT_URL = \"https://console.cloud.google.com/billing/create?inv=1&invt=Ab4E_Q\"\n",
    "CREATE_BILLING_ACCOUNT_OPTION = \"‚Üí Create New Billing Account\"\n",
    "MODEL_OPTIONS = {\n",
    "    \"Gemini 2.5 Flash (Default)\": \"gemini-2.5-flash\",\n",
    "    \"Gemini 2.5 Pro\": \"gemini-2.5-pro\"\n",
    "}\n",
    "SAMPLE_CASE = \"\"\"A now almost 4-year-old female diagnosed with KMT2A-rearranged AML and CNS2 involvement exhibited refractory disease after NOPHO DBH AML 2012 protocol. Post- MEC and ADE, MRD remained at 35% and 53%. Vyxeos-clofarabine therapy reduced MRD to 18%. Third-line FLAG-Mylotarg lowered MRD to 3.5% (flow) and 1% (molecular). After a cord blood HSCT in December 2022, she relapsed 10 months later with 3% MRD and femoral extramedullary disease.\n",
    "After the iLTB discussion, in November 2023 the patient was enrolled in the SNDX5613 trial, receiving revumenib for three months, leading to a reduction in KMT2A MRD to 0.1% by PCR. Subsequently, the patient underwent a second allogeneic HSCT using cord blood with treosulfan, thiotepa, and fludarabine conditioning, followed by revumenib maintenance. In August 2024, 6.5 months after the second HSCT, the patient experienced a bone marrow relapse with 33% blasts. The patient is currently in very good clinical condition.\n",
    "\n",
    "Diagnostic tests:\t\t\t\n",
    "WES and RNAseq were performed on the 1st relapse sample showing KMT2A::MLLT3 fusion and NRAS (p.Gln61Lys) mutation.\n",
    "Flow cytometry from the current relapse showed positive CD33 and CD123.\n",
    "WES and RNAseq of the current relapse sample is pending.\"\"\"\n",
    "\n",
    "# --- Global Variables ---\n",
    "genai_client, bq_client = None, None\n",
    "journal_impact_dict = {}\n",
    "PROJECT_ID = \"\"\n",
    "LOCATION = \"global\"\n",
    "USER_DATASET = \"pubmed\"\n",
    "\n",
    "# Disease extraction prompt from gemini-medical-literature\n",
    "DISEASE_EXTRACTION_PROMPT = \"\"\"You are an expert pediatric oncologist analyzing patient case notes to identify the primary disease.\n",
    "\n",
    "Task: Extract the initial diagnosis exactly as written in the case notes.\n",
    "\n",
    "Examples:\n",
    "- Input: \"A now almost 4-year-old female diagnosed with KMT2A-rearranged AML and CNS2 involvement...\"\n",
    "  Output: AML\n",
    "\n",
    "- Input: \"18 y/o boy, diagnosed in November 2021 with T-ALL with CNS1...\"\n",
    "  Output: T-ALL\n",
    "\n",
    "- Input: \"A 10-year-old patient with relapsed B-cell acute lymphoblastic leukemia (B-ALL)...\"\n",
    "  Output: B-cell acute lymphoblastic leukemia (B-ALL)\n",
    "\n",
    "Output only the disease name. No additional text or formatting.\n",
    "\"\"\"\n",
    "\n",
    "# Generic final analysis prompt template\n",
    "FINAL_ANALYSIS_PROMPT_TEMPLATE = \"\"\"You are a research analyst synthesizing findings from a comprehensive literature review. Your goal is to provide insights that are valuable for research purposes.\n",
    "\n",
    "RESEARCH CONTEXT:\n",
    "Original Query/Case: {case_description}\n",
    "\n",
    "Primary Focus: {primary_focus}\n",
    "Key Concepts Searched: {key_concepts}\n",
    "\n",
    "ANALYZED ARTICLES:\n",
    "{articles_content}\n",
    "\n",
    "Based on the research context and analyzed articles above, please provide a comprehensive synthesis in markdown format with the following sections:\n",
    "\n",
    "## Literature Analysis: {primary_focus}\n",
    "\n",
    "### 1. Executive Summary\n",
    "Provide a concise overview of the key findings from the literature review, highlighting:\n",
    "- Main themes identified across the literature\n",
    "- Most significant insights relevant to the research query  \n",
    "- Overall quality and quantity of available evidence\n",
    "- Key takeaways for researchers in this field\n",
    "\n",
    "### 2. Key Findings by Concept\n",
    "| Concept | Articles Discussing | Key Findings | Evidence Quality |\n",
    "|---------|-------------------|--------------|------------------|\n",
    "[For each key concept searched, summarize what the literature reveals about it]\n",
    "\n",
    "### 3. Methodological Landscape\n",
    "| Research Method | Frequency | Notable Studies | Insights Generated |\n",
    "|-----------------|-----------|-----------------|-------------------|\n",
    "[Map the research methodologies used across the analyzed articles]\n",
    "\n",
    "### 4. Temporal Trends\n",
    "| Time Period | Research Focus | Key Developments | Paradigm Shifts |\n",
    "|-------------|----------------|------------------|-----------------|\n",
    "[Analyze how research in this area has evolved over time]\n",
    "\n",
    "### 5. Cross-Study Patterns\n",
    "| Pattern | Supporting Evidence | Implications | Confidence Level |\n",
    "|---------|-------------------|--------------|------------------|\n",
    "[Identify patterns that appear across multiple studies]\n",
    "\n",
    "### 6. Controversies & Unresolved Questions\n",
    "| Issue | Different Perspectives | Evidence For/Against | Current Consensus |\n",
    "|-------|----------------------|---------------------|-------------------|\n",
    "[Highlight areas of disagreement or ongoing debate in the literature]\n",
    "\n",
    "### 7. Knowledge Gaps & Future Research\n",
    "| Gap Identified | Why It Matters | Potential Approaches | Expected Impact |\n",
    "|----------------|----------------|---------------------|-----------------|\n",
    "[Map areas where further research is needed]\n",
    "\n",
    "### 8. Practical Applications\n",
    "Based on the synthesized literature, identify:\n",
    "- How these findings can be applied in practice\n",
    "- Recommendations for researchers entering this field\n",
    "- Tools, methods, or frameworks that emerge from the literature\n",
    "- Potential interdisciplinary connections\n",
    "\n",
    "### 9. Quality & Reliability Assessment\n",
    "Evaluate the overall body of literature:\n",
    "- **Study Types**: Distribution of research designs (experimental, observational, reviews, etc.)\n",
    "- **Sample Characteristics**: Common sample sizes, populations studied\n",
    "- **Geographic Distribution**: Where research is being conducted\n",
    "- **Publication Patterns**: Journal quality, publication years, citation patterns\n",
    "- **Methodological Rigor**: Strengths and limitations observed\n",
    "\n",
    "### 10. Synthesis & Conclusions\n",
    "Provide an integrated narrative that:\n",
    "- Connects findings across all analyzed articles\n",
    "- Identifies the strongest evidence and most reliable findings\n",
    "- Suggests how this research area is likely to develop\n",
    "- Offers guidance for stakeholders interested in this topic\n",
    "\n",
    "### 11. Bibliography\n",
    "**Most Relevant Articles** (in order of relevance to the research query):\n",
    "[Format each as: Title, Authors, Journal (Year), [PMID: xxxxx](https://pubmed.ncbi.nlm.nih.gov/xxxxx/)]\n",
    "\n",
    "---\n",
    "\n",
    "IMPORTANT NOTES:\n",
    "- Maintain objectivity and clearly distinguish between strong evidence and preliminary findings\n",
    "- Use accessible language while preserving scientific accuracy\n",
    "- All claims must be traceable to specific articles in the analysis\n",
    "- When evidence is conflicting, present all viewpoints fairly\n",
    "- Focus on research insights and knowledge synthesis rather than prescriptive recommendations\n",
    "- Highlight both the strengths and limitations of the current literature\n",
    "\"\"\"\n",
    "\n",
    "# Events extraction prompt - updated to extract general concepts for better literature matching\n",
    "EVENT_EXTRACTION_PROMPT = \"\"\"You are an expert pediatric oncologist analyzing patient case notes to identify key disease concepts and clinical features for literature search.\n",
    "\n",
    "Task: Extract 5 general medical concepts that would help find relevant literature. Focus on:\n",
    "- Disease types and subtypes (e.g., \"AML\", \"T-ALL\", \"B-ALL\")\n",
    "- Genetic alterations (gene names only, e.g., \"KMT2A rearrangement\", \"FLT3 mutation\", \"TP53 mutation\")\n",
    "- Treatment modalities (e.g., \"HSCT\", \"chemotherapy\", \"CAR-T therapy\", \"stem cell transplant\")\n",
    "- General complications (e.g., \"relapse\", \"refractory disease\", \"CNS involvement\", \"MRD positive\")\n",
    "- Anatomical sites or disease features (e.g., \"bone marrow\", \"extramedullary disease\")\n",
    "\n",
    "Instructions:\n",
    "- Extract GENERAL CONCEPTS that appear in medical literature\n",
    "- DO NOT include patient-specific details like percentages, timeframes, or specific protocol names\n",
    "- Focus on searchable medical terms\n",
    "- Output exactly 5 concepts\n",
    "\n",
    "Example:\n",
    "Input: \"A 4-year-old female with KMT2A-rearranged AML and CNS2 involvement exhibited refractory disease after NOPHO protocol. MRD remained at 35%. She relapsed 10 months after cord blood HSCT with 33% blasts. WES showed KMT2A::MLLT3 fusion and NRAS mutation.\"\n",
    "\n",
    "Output: \"AML\" \"KMT2A rearrangement\" \"CNS involvement\" \"refractory disease\" \"HSCT relapse\"\n",
    "\n",
    "Output only 5 general medical concepts, one per line in quotes. No additional text or formatting.\n",
    "\"\"\"\n",
    "\n",
    "# --- Helper Functions for Enhanced Setup ---\n",
    "def list_projects():\n",
    "    \"\"\"List all available Google Cloud projects.\"\"\"\n",
    "    try:\n",
    "        client = resourcemanager_v3.ProjectsClient(credentials=CREDENTIALS)\n",
    "        projects = []\n",
    "        request = resourcemanager_v3.SearchProjectsRequest(query=\"\")\n",
    "        for project in client.search_projects(request=request):\n",
    "            if project.state == resourcemanager_v3.Project.State.ACTIVE:\n",
    "                projects.append({\n",
    "                    \"id\": project.project_id,\n",
    "                    \"name\": project.display_name,\n",
    "                    \"number\": project.name.split('/')[-1]\n",
    "                })\n",
    "        return sorted(projects, key=lambda p: p['id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing projects: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_billing_enabled(project_id):\n",
    "    \"\"\"Check if billing is enabled for a project.\"\"\"\n",
    "    try:\n",
    "        client = billing_v1.CloudBillingClient(credentials=CREDENTIALS)\n",
    "        billing_info = client.get_project_billing_info(name=f\"projects/{project_id}\")\n",
    "        return billing_info.billing_enabled\n",
    "    except Exception as e:\n",
    "        print(f\"Could not check billing for project {project_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "def list_enabled_apis(project_id):\n",
    "    \"\"\"List enabled APIs for a project.\"\"\"\n",
    "    try:\n",
    "        client = service_usage_v1.ServiceUsageClient(credentials=CREDENTIALS)\n",
    "        request = service_usage_v1.ListServicesRequest(\n",
    "            parent=f\"projects/{project_id}\",\n",
    "            filter=\"state:ENABLED\"\n",
    "        )\n",
    "        enabled_apis = [service.name.split('/')[-1] for service in client.list_services(request=request)]\n",
    "        return enabled_apis\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing APIs: {e}\")\n",
    "        return []\n",
    "\n",
    "def enable_apis(project_id, apis_to_enable, progress=gr.Progress()):\n",
    "    \"\"\"Enable a list of APIs for a project.\"\"\"\n",
    "    client = service_usage_v1.ServiceUsageClient(credentials=CREDENTIALS)\n",
    "    total_apis = len(apis_to_enable)\n",
    "    for i, api_name in enumerate(apis_to_enable):\n",
    "        progress((i + 1) / total_apis, desc=f\"Enabling {api_name}...\")\n",
    "        try:\n",
    "            request = service_usage_v1.EnableServiceRequest(name=f\"projects/{project_id}/services/{api_name}\")\n",
    "            operation = client.enable_service(request=request)\n",
    "            operation.result(timeout=300)  # Wait for completion\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error enabling API {api_name}: {e}\")\n",
    "    return True\n",
    "\n",
    "def list_billing_accounts():\n",
    "    \"\"\"Lists available billing accounts and adds an option to create a new one.\"\"\"\n",
    "    try:\n",
    "        client = billing_v1.CloudBillingClient(credentials=CREDENTIALS)\n",
    "        accounts = client.list_billing_accounts()\n",
    "        account_names = [f\"{acc.display_name} ({acc.name.split('/')[-1]})\" for acc in accounts if acc.open]\n",
    "        return account_names + [CREATE_BILLING_ACCOUNT_OPTION]\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing billing accounts: {e}\")\n",
    "        return [CREATE_BILLING_ACCOUNT_OPTION]\n",
    "\n",
    "def create_new_project(project_id, billing_account_name, model_endpoint, thinking_budget, progress=gr.Progress()):\n",
    "    \"\"\"Creates a new GCP project, links billing, and enables necessary APIs.\"\"\"\n",
    "    global MODEL_ID, THINKING_BUDGET\n",
    "    try:\n",
    "        # Update global model settings\n",
    "        MODEL_ID = model_endpoint\n",
    "        THINKING_BUDGET = thinking_budget\n",
    "        \n",
    "        progress(0.1, desc=\"Creating project...\")\n",
    "        project_client = resourcemanager_v3.ProjectsClient(credentials=CREDENTIALS)\n",
    "        project = {'project_id': project_id, 'display_name': project_id}\n",
    "        operation = project_client.create_project(project=project)\n",
    "        created_project = operation.result(timeout=300)\n",
    "\n",
    "        progress(0.4, desc=\"Linking billing account...\")\n",
    "        billing_client = billing_v1.CloudBillingClient(credentials=CREDENTIALS)\n",
    "        billing_account_id = billing_account_name.split(' ')[-1].strip('()')\n",
    "        project_billing_info = {'billing_account_name': f\"billingAccounts/{billing_account_id}\"}\n",
    "        billing_client.update_project_billing_info(\n",
    "            name=f\"projects/{created_project.project_id}\",\n",
    "            project_billing_info=project_billing_info\n",
    "        )\n",
    "\n",
    "        progress(0.6, desc=\"Enabling APIs...\")\n",
    "        enable_apis(project_id, REQUIRED_APIS, progress)\n",
    "\n",
    "        # Add a delay to ensure project propagation and IAM permissions\n",
    "        progress(0.7, desc=\"Waiting for project propagation...\")\n",
    "        time.sleep(10)  # 10-second delay for IAM permissions to propagate\n",
    "\n",
    "        # Use the shared setup logic with model endpoint\n",
    "        global genai_client, bq_client, journal_impact_dict\n",
    "        genai_client, bq_client, journal_impact_dict = setup_project(project_id, LOCATION, USER_DATASET, model_endpoint, progress)\n",
    "\n",
    "        return f\"‚úÖ Project '{project_id}' created and set up.\", f\"{project_id} ({project_id})\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error creating project: {e}\", None\n",
    "\n",
    "def link_billing_to_project(project_id, billing_account_name):\n",
    "    \"\"\"Links an existing billing account to a project.\"\"\"\n",
    "    try:\n",
    "        billing_client = billing_v1.CloudBillingClient(credentials=CREDENTIALS)\n",
    "        billing_account_id = billing_account_name.split(' ')[-1].strip('()')\n",
    "        project_billing_info = {'billing_account_name': f\"billingAccounts/{billing_account_id}\"}\n",
    "        billing_client.update_project_billing_info(\n",
    "            name=f\"projects/{project_id}\",\n",
    "            project_billing_info=project_billing_info\n",
    "        )\n",
    "        return True, \"‚úÖ Billing account linked successfully!\"\n",
    "    except Exception as e:\n",
    "        return False, f\"‚ùå Error linking billing account: {e}\"\n",
    "\n",
    "# --- Core Functions ---\n",
    "def setup_project(project_id, location, dataset, model_endpoint, progress=gr.Progress()):\n",
    "    \"\"\"Common setup logic for both new and existing projects.\"\"\"\n",
    "    try:\n",
    "        # Set environment variable\n",
    "        os.environ['GOOGLE_CLOUD_PROJECT'] = project_id\n",
    "        \n",
    "        progress(0.7, desc=\"Initializing clients...\")\n",
    "        genai_client, bq_client = init_clients(project_id, location)\n",
    "        if not genai_client or not bq_client:\n",
    "            raise ConnectionError(\"Failed to initialize Google Cloud clients.\")\n",
    "\n",
    "        # Setup BigQuery dataset and model with selected model endpoint\n",
    "        setup_bigquery(project_id, dataset, bq_client, model_endpoint, progress)\n",
    "\n",
    "        progress(0.9, desc=\"Loading journal data...\")\n",
    "        journal_impact_dict = load_journal_data(bq_client)\n",
    "        \n",
    "        return genai_client, bq_client, journal_impact_dict\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def init_clients(project_id, location):\n",
    "    \"\"\"Initialize clients with retry logic for newly created projects.\"\"\"\n",
    "    max_retries = 3\n",
    "    retry_delays = [5, 10, 15]  # Delays in seconds between retries\n",
    "    \n",
    "    # Ensure the project ID is set in the environment\n",
    "    os.environ['GOOGLE_CLOUD_PROJECT'] = project_id\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempting to initialize clients for project {project_id} (attempt {attempt + 1}/{max_retries})...\")\n",
    "            \n",
    "            genai_client = genai.Client(vertexai=True, project=project_id, location=location, credentials=CREDENTIALS)\n",
    "            bq_client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n",
    "            \n",
    "            # Test BigQuery access\n",
    "            test_query = \"SELECT 1\"\n",
    "            bq_client.query(test_query).result()\n",
    "            \n",
    "            print(f\"Successfully initialized clients for project {project_id}\")\n",
    "            return genai_client, bq_client\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                delay = retry_delays[attempt]\n",
    "                print(f\"Waiting {delay} seconds before retry...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"All {max_retries} attempts failed. Error initializing clients for project {project_id}: {e}\")\n",
    "                return None, None\n",
    "\n",
    "def load_journal_data(bq_client_param=None):\n",
    "    \"\"\"Load journal data from BigQuery instead of CSV.\"\"\"\n",
    "    try:\n",
    "        # Use provided client or global client\n",
    "        client = bq_client_param or bq_client\n",
    "        if client is None:\n",
    "            print(\"BigQuery client not initialized\")\n",
    "            return {}\n",
    "            \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            journal_title,\n",
    "            sjr\n",
    "        FROM `{PROJECT_ID}.{USER_DATASET}.journal_impact`\n",
    "        WHERE sjr IS NOT NULL\n",
    "        ORDER BY sjr DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Loading journal data from BigQuery...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = client.query(query).to_dataframe()\n",
    "        \n",
    "        # Convert to dictionary\n",
    "        sjr_dict = {}\n",
    "        for _, row in results.iterrows():\n",
    "            sjr_dict[row['journal_title']] = row['sjr']\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Loaded {len(sjr_dict)} journals from BigQuery in {load_time:.2f} seconds\")\n",
    "        return sjr_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading journal data from BigQuery: {e}\")\n",
    "        return {}\n",
    "\n",
    "def setup_journal_impact_table(bq_client, project_id, dataset_id, progress=gr.Progress()):\n",
    "    \"\"\"Create and populate journal impact table if it doesn't exist.\"\"\"\n",
    "    table_id = \"journal_impact\"\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    \n",
    "    try:\n",
    "        # Check if table exists\n",
    "        try:\n",
    "            table = bq_client.get_table(table_ref)\n",
    "            print(f\"Journal impact table already exists with {table.num_rows} rows\")\n",
    "            return True\n",
    "        except:\n",
    "            # Table doesn't exist, create it\n",
    "            progress(0.85, desc=\"Creating journal impact table...\")\n",
    "            print(f\"Creating journal impact table: {table_ref}\")\n",
    "            \n",
    "            # Download and parse CSV\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(JOURNAL_IMPACT_CSV_URL, sep=';')\n",
    "            \n",
    "            # Convert SJR values from string with commas to float\n",
    "            df['SJR_float'] = df['SJR'].apply(lambda x: float(str(x).replace(',', '')) if pd.notna(x) and str(x) != '' else None)\n",
    "            \n",
    "            # Select relevant columns and rename\n",
    "            columns_to_keep = {\n",
    "                'Title': 'journal_title',\n",
    "                'SJR_float': 'sjr',\n",
    "                'Issn': 'issn',\n",
    "                'SJR Best Quartile': 'sjr_best_quartile',\n",
    "                'H index': 'h_index',\n",
    "                'Publisher': 'publisher',\n",
    "                'Categories': 'categories',\n",
    "                'Country': 'country',\n",
    "                'Type': 'type'\n",
    "            }\n",
    "            \n",
    "            df_clean = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "            \n",
    "            # Remove rows with no SJR value\n",
    "            df_clean = df_clean[df_clean['sjr'].notna()]\n",
    "            \n",
    "            print(f\"Cleaned data: {len(df_clean)} rows with valid SJR values\")\n",
    "            \n",
    "            # Define table schema\n",
    "            schema = [\n",
    "                bigquery.SchemaField(\"journal_title\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"sjr\", \"FLOAT64\"),\n",
    "                bigquery.SchemaField(\"issn\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"sjr_best_quartile\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"h_index\", \"INT64\"),\n",
    "                bigquery.SchemaField(\"publisher\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"categories\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"country\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"type\", \"STRING\"),\n",
    "            ]\n",
    "            \n",
    "            # Configure load job\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                schema=schema,\n",
    "                write_disposition=\"WRITE_TRUNCATE\",\n",
    "            )\n",
    "            \n",
    "            # Load data\n",
    "            print(f\"Uploading {len(df_clean)} rows to {table_ref}...\")\n",
    "            job = bq_client.load_table_from_dataframe(df_clean, table_ref, job_config=job_config)\n",
    "            job.result()  # Wait for job to complete\n",
    "            \n",
    "            # Verify upload\n",
    "            table = bq_client.get_table(table_ref)\n",
    "            print(f\"‚úÖ Successfully created journal impact table with {table.num_rows} rows\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up journal impact table: {e}\")\n",
    "        # Continue without journal impact data\n",
    "        return False\n",
    "\n",
    "def extract_medical_info(case_text, client, disease_prompt=None, events_prompt=None):\n",
    "    \"\"\"Extract medical information using custom or default prompts.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Use provided prompts or defaults\n",
    "    if not disease_prompt:\n",
    "        disease_prompt = DISEASE_EXTRACTION_PROMPT\n",
    "    if not events_prompt:\n",
    "        events_prompt = EVENT_EXTRACTION_PROMPT\n",
    "    \n",
    "    full_disease_prompt = f\"{disease_prompt}\\n\\nCase notes:\\n{case_text}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID, \n",
    "        contents=[full_disease_prompt], \n",
    "        config=GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET)\n",
    "        )\n",
    "    )\n",
    "    results[\"disease\"] = response.text.strip()\n",
    "    \n",
    "    full_events_prompt = f\"{events_prompt}\\n\\nCase notes:\\n{case_text}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID, \n",
    "        contents=[full_events_prompt], \n",
    "        config=GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET)\n",
    "        )\n",
    "    )\n",
    "    results[\"events\"] = response.text.strip()\n",
    "    \n",
    "    # Generate event IDs for the extracted events\n",
    "    events_text = results[\"events\"]\n",
    "    events_list = []\n",
    "    events_with_ids = {}\n",
    "    \n",
    "    # Parse events (handle both line-separated and quote-separated formats)\n",
    "    if '\"' in events_text:\n",
    "        # Events are in quotes\n",
    "        import re\n",
    "        events_list = re.findall(r'\"([^\"]+)\"', events_text)\n",
    "    else:\n",
    "        # Events are line-separated\n",
    "        events_list = [e.strip() for e in events_text.split('\\n') if e.strip()]\n",
    "    \n",
    "    # Create ID mapping\n",
    "    for i, event in enumerate(events_list, 1):\n",
    "        event_id = f\"event_{i}\"\n",
    "        events_with_ids[event_id] = event\n",
    "    \n",
    "    results[\"events_list\"] = events_list\n",
    "    results[\"events_with_ids\"] = events_with_ids\n",
    "    \n",
    "    return results\n",
    "\n",
    "def search_pubmed_articles(disease, events, bq_client, embedding_model, pubmed_table, top_k, offset=0):\n",
    "    query_text = f\"{disease} {' '.join(events)}\"\n",
    "    # Debug: print the project being used\n",
    "    print(f\"Using BigQuery project: {bq_client.project}\")\n",
    "    print(f\"Using embedding model: {embedding_model}\")\n",
    "    print(f\"Searching with top_k={top_k}, offset={offset}\")\n",
    "    \n",
    "    # Use DECLARE/SET pattern to safely handle special characters in query text\n",
    "    sql = f\"\"\"\n",
    "    DECLARE query_text STRING;\n",
    "    SET query_text = \\\"\\\"\\\"\n",
    "{query_text}\n",
    "\\\"\\\"\\\";\n",
    "    \n",
    "    WITH vector_results AS (\n",
    "        SELECT base.name AS PMCID, base.PMID, base.content, distance \n",
    "        FROM VECTOR_SEARCH(\n",
    "            TABLE `{pubmed_table}`, \n",
    "            'ml_generate_embedding_result', \n",
    "            (SELECT ml_generate_embedding_result \n",
    "             FROM ML.GENERATE_EMBEDDING(\n",
    "                 MODEL `{embedding_model}`, \n",
    "                 (SELECT query_text AS content)\n",
    "             )), \n",
    "            top_k => {top_k + offset}\n",
    "        )\n",
    "    )\n",
    "    SELECT * FROM vector_results\n",
    "    ORDER BY distance\n",
    "    LIMIT {top_k}\n",
    "    OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    return bq_client.query(sql).to_dataframe()\n",
    "\n",
    "def lookup_journal_impact_score(journal_title, journal_dict, genai_client):\n",
    "    \"\"\"Look up journal impact score using Gemini API with structured response.\"\"\"\n",
    "    if not journal_title or not genai_client:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Build journal context for Gemini\n",
    "        journal_context = \"\\n\".join([f\"{title}: {sjr}\" for title, sjr in journal_dict.items()])\n",
    "        \n",
    "        prompt = f\"\"\"Given the journal title \"{journal_title}\", find the matching journal from the list below and return its SJR score.\n",
    "\n",
    "Journal SJR scores:\n",
    "{journal_context}\n",
    "\n",
    "Return the SJR score as an integer. If no match is found or the score is NaN/invalid, return 0.\"\"\"\n",
    "        \n",
    "        # Use structured response configuration\n",
    "        from google.genai import types\n",
    "        \n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema={\"type\": \"OBJECT\", \"properties\": {\"sjr_score\": {\"type\": \"INTEGER\"}}},\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET)\n",
    "        )\n",
    "        \n",
    "        response = genai_client.models.generate_content(\n",
    "            model=MODEL_ID, \n",
    "            contents=[prompt], \n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            result = json.loads(response.text)\n",
    "            score = result.get('sjr_score', 0)\n",
    "            lookup_time = time.time() - start_time\n",
    "            print(f\"   üîç Gemini journal lookup for '{journal_title}' took {lookup_time:.2f} seconds (found SJR: {score})\")\n",
    "            return score if score >= 0 else 0\n",
    "        except json.JSONDecodeError:\n",
    "            lookup_time = time.time() - start_time\n",
    "            print(f\"   üîç Gemini journal lookup for '{journal_title}' took {lookup_time:.2f} seconds (parse error)\")\n",
    "            return 0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error looking up journal impact score: {e}\")\n",
    "        return 0\n",
    "\n",
    "def calculate_dynamic_score(metadata, criteria_list, journal_dict):\n",
    "    \"\"\"Calculate article score based on dynamic criteria configuration.\"\"\"\n",
    "    score = 0\n",
    "    breakdown = {}\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    for criterion in criteria_list:\n",
    "        # Skip if weight is 0\n",
    "        if criterion['weight'] == 0:\n",
    "            continue\n",
    "            \n",
    "        criterion_type = criterion.get('type', 'boolean')\n",
    "        criterion_name = criterion['name']\n",
    "        \n",
    "        if criterion_type == 'special_journal':\n",
    "            # Look up journal impact score using Gemini\n",
    "            journal_title = metadata.get('journal_title', '')\n",
    "            sjr = lookup_journal_impact_score(journal_title, journal_dict, genai_client)\n",
    "            \n",
    "            if sjr > 0:\n",
    "                # Apply logarithmic scaling with a cap to prevent domination\n",
    "                # Log scale: log(sjr + 1) * 10, capped at 100\n",
    "                normalized_sjr = min(math.log(sjr + 1) * 10, 100)\n",
    "                weighted_score = normalized_sjr * (criterion['weight'] / 100)\n",
    "                score += weighted_score\n",
    "                breakdown['journal_impact'] = round(weighted_score, 2)\n",
    "                \n",
    "        elif criterion_type == 'special_year':\n",
    "            # Enhanced year penalty with exponential decay\n",
    "            year_value = metadata.get('year')\n",
    "            if year_value is not None and year_value != '':\n",
    "                try:\n",
    "                    # Handle both string and int types\n",
    "                    if isinstance(year_value, str):\n",
    "                        # Remove any quotes or whitespace\n",
    "                        year_value = year_value.strip().strip('\"').strip(\"'\")\n",
    "                    article_year = int(year_value)\n",
    "                    \n",
    "                    if article_year > 1900 and article_year <= current_year:  # Sanity check\n",
    "                        year_diff = current_year - article_year\n",
    "                        # Exponential decay: penalty grows exponentially with age\n",
    "                        # Base penalty of -10, multiplied by 1.2^year_diff\n",
    "                        year_penalty = -10 * (1.2 ** min(year_diff, 10))  # Cap at 10 years to prevent overflow\n",
    "                        # Apply user's weight as a multiplier\n",
    "                        weighted_penalty = year_penalty * criterion['weight'] / 100  # Normalize weight\n",
    "                        score += weighted_penalty\n",
    "                        breakdown['year'] = round(weighted_penalty, 2)\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    print(f\"Warning: Could not process year '{year_value}': {e}\")\n",
    "                    pass\n",
    "                    \n",
    "        elif criterion_type == 'numeric':\n",
    "            # For numeric criteria, multiply value by weight\n",
    "            value = metadata.get(criterion_name, 0)\n",
    "            if isinstance(value, (int, float)):\n",
    "                weighted_value = value * criterion['weight']\n",
    "                score += weighted_value\n",
    "                breakdown[criterion_name] = round(weighted_value, 2)\n",
    "                \n",
    "        elif criterion_type == 'direct':\n",
    "            # For direct scoring, use the value as-is (ignore weight)\n",
    "            value = metadata.get(criterion_name, 0)\n",
    "            if isinstance(value, (int, float)):\n",
    "                score += value\n",
    "                breakdown[criterion_name] = round(value, 2)\n",
    "                \n",
    "        else:\n",
    "            # Default: boolean criteria\n",
    "            if metadata.get(criterion_name):\n",
    "                score += criterion['weight']\n",
    "                breakdown[criterion_name] = criterion['weight']\n",
    "                \n",
    "    return round(score, 2), breakdown\n",
    "\n",
    "def analyze_event_coverage_batch(df, disease, events_with_ids, bq_client):\n",
    "    \"\"\"Phase 1: Analyze articles for event coverage using AI.GENERATE_TABLE.\"\"\"\n",
    "    global PROJECT_ID, USER_DATASET, PUBMED_TABLE\n",
    "    \n",
    "    if df.empty:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüìä Phase 1: Checking event coverage for {len(df)} article(s)...\")\n",
    "        coverage_start_time = time.time()\n",
    "        \n",
    "        # Build event list with IDs for the prompt\n",
    "        event_list_text = \"\\n\".join([f\"- {event_id}: \\\"{event_text}\\\"\" \n",
    "                                     for event_id, event_text in events_with_ids.items()])\n",
    "        \n",
    "        # Get PMCIDs from dataframe (using name field as primary identifier)\n",
    "        # Handle cases where PMCID might be None\n",
    "        pmcids = [str(pmcid) for pmcid in df['PMCID'].tolist() if pmcid is not None]\n",
    "        if not pmcids:\n",
    "            print(\"Warning: No valid PMCIDs found in batch\")\n",
    "            return []\n",
    "        pmcids_str = \"', '\".join(pmcids)\n",
    "        \n",
    "        # Build PMCID to name mapping for prompt\n",
    "        pmcid_mapping = {}\n",
    "        for _, row in df.iterrows():\n",
    "            pmcid_mapping[str(row['PMCID'])] = str(row['PMCID'])\n",
    "        \n",
    "        # Simple prompt focused only on event detection\n",
    "        coverage_prompt = f\"\"\"You are analyzing medical literature to identify which events from a patient case are mentioned in each article.\n",
    "\n",
    "Master events from patient case:\n",
    "{event_list_text}\n",
    "\n",
    "IMPORTANT: You must return JSON with one field:\n",
    "- event_ids: Comma-separated event IDs found (e.g., \"event_1,event_3\"), or empty string if no events found\n",
    "\n",
    "Article PMCID: {{PMCID}}\n",
    "Article content:\n",
    "\"\"\"\n",
    "        \n",
    "        # Escape triple quotes if needed\n",
    "        coverage_prompt_escaped = coverage_prompt.replace('\"\"\"', '\\\\\"\"\"')\n",
    "        \n",
    "        # Schema only includes event_ids (name will be passed through automatically)\n",
    "        schema = \"event_ids STRING\"\n",
    "        \n",
    "        # Construct AI.GENERATE_TABLE query for batch processing using PMCID\n",
    "        query = f'''\n",
    "        SELECT \n",
    "            name AS PMCID,\n",
    "            event_ids\n",
    "        FROM \n",
    "        AI.GENERATE_TABLE(\n",
    "            MODEL `{PROJECT_ID}.{USER_DATASET}.gemini_generation`,\n",
    "            (\n",
    "                SELECT \n",
    "                    name,\n",
    "                    CONCAT(\n",
    "                        REPLACE(\"\"\"{coverage_prompt_escaped}\"\"\", '{{PMCID}}', name),\n",
    "                        content\n",
    "                    ) AS prompt\n",
    "                FROM `{PUBMED_TABLE}`\n",
    "                WHERE name IN ('{pmcids_str}')\n",
    "            ),\n",
    "            STRUCT(\n",
    "                \"{schema}\" AS output_schema,\n",
    "                4096 AS max_output_tokens,\n",
    "                0 AS temperature,\n",
    "                0.95 AS top_p\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        # Execute query\n",
    "        results_df = bq_client.query(query).to_dataframe()\n",
    "        \n",
    "        # Convert to list of dictionaries\n",
    "        results = []\n",
    "        for _, row in results_df.iterrows():\n",
    "            result = {\n",
    "                'PMCID': row['PMCID'],\n",
    "                'event_ids': row.get('event_ids', '').strip()\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        coverage_time = time.time() - coverage_start_time\n",
    "        print(f\"   ‚úÖ Event coverage check completed in {coverage_time:.2f} seconds\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in event coverage analysis: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def build_dynamic_schema(criteria):\n",
    "    \"\"\"Build dynamic BigQuery schema based on criteria configuration.\"\"\"\n",
    "    # Start with standard fields\n",
    "    schema_parts = [\n",
    "        \"title STRING\",\n",
    "        \"journal_title STRING\", \n",
    "        \"year STRING\", \n",
    "        \"paper_type STRING\",\n",
    "        \"actionable_events STRING\"\n",
    "    ]\n",
    "    \n",
    "    # Add fields for each criterion based on type\n",
    "    for criterion in criteria:\n",
    "        if criterion['name'] not in ['journal_impact', 'year']:  # Skip special ones already handled\n",
    "            if criterion['type'] == 'boolean':\n",
    "                schema_parts.append(f\"{criterion['name']} BOOL\")\n",
    "            elif criterion['type'] in ['numeric', 'direct']:\n",
    "                schema_parts.append(f\"{criterion['name']} INT64\")\n",
    "    \n",
    "    return \",\\n    \".join(schema_parts)\n",
    "\n",
    "def analyze_article_batch_with_criteria(df, disease, events, bq_client, journal_dict, persona, criteria):\n",
    "    \"\"\"Analyze articles using AI.GENERATE_TABLE directly on BigQuery table.\"\"\"\n",
    "    global PROJECT_ID, USER_DATASET, PUBMED_TABLE\n",
    "    \n",
    "    if df.empty:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüìä Starting AI.GENERATE_TABLE analysis for {len(df)} article(s)...\")\n",
    "        ai_start_time = time.time()\n",
    "        # Build criteria instructions\n",
    "        criteria_instructions = []\n",
    "        for criterion in criteria:\n",
    "            if criterion['name'] not in ['journal_impact', 'year']:\n",
    "                if criterion['type'] == 'boolean':\n",
    "                    criteria_instructions.append(f\"- {criterion['name']} (boolean): {criterion['description']}\")\n",
    "                elif criterion['type'] == 'numeric':\n",
    "                    criteria_instructions.append(f\"- {criterion['name']} (number): {criterion['description']} (Return 0 if unknown)\")\n",
    "                elif criterion['type'] == 'direct':\n",
    "                    criteria_instructions.append(f\"- {criterion['name']} (number 0-100): {criterion['description']} (Return 0 if no matches or unknown)\")\n",
    "        \n",
    "        criteria_text = \"\\n\".join(criteria_instructions) if criteria_instructions else \"\"\n",
    "        \n",
    "        # Build dynamic schema\n",
    "        schema = build_dynamic_schema(criteria)\n",
    "        \n",
    "        # Build the complete prompt in Python first\n",
    "        full_prompt = f\"\"\"{persona}\n",
    "\n",
    "Analyze this article for relevance to:\n",
    "Disease: {disease}\n",
    "Events: {', '.join(events)}\n",
    "\n",
    "For each article, extract the following information:\n",
    "1. Standard fields (always extract these):\n",
    "   - title: Article title (if unknown, return empty string)\n",
    "   - journal_title: Name of the journal (if unknown, return empty string)\n",
    "   - year: Publication year as a string (e.g., \"2023\"). If unknown or not found, return empty string, NOT null or NaN\n",
    "   - paper_type: Type of paper (e.g., clinical trial, review, case report)\n",
    "   - actionable_events: Comma-separated list of events found in the article\n",
    "\n",
    "2. Evaluation criteria:\n",
    "{criteria_text}\n",
    "\n",
    "IMPORTANT: For all numeric fields, always return 0 instead of null, NaN, or leaving the field empty.\n",
    "\n",
    "Article content:\n",
    "\"\"\"\n",
    "        \n",
    "        # Escape triple quotes if they appear in the prompt (unlikely but safe)\n",
    "        full_prompt_escaped = full_prompt.replace('\"\"\"', '\\\\\"\"\"')\n",
    "        \n",
    "        # Get PMCIDs from dataframe (using name field as primary identifier)\n",
    "        # Handle cases where PMCID might be None\n",
    "        pmcids = [str(pmcid) for pmcid in df['PMCID'].tolist() if pmcid is not None]\n",
    "        if not pmcids:\n",
    "            print(\"Warning: No valid PMCIDs found in batch for full analysis\")\n",
    "            return []\n",
    "        pmcids_str = \"', '\".join(pmcids)\n",
    "        \n",
    "        # Format schema for single line\n",
    "        schema_single_line = schema.replace('\\n', ' ').replace('    ', '')\n",
    "        \n",
    "        # Construct AI.GENERATE_TABLE query using PMCID as primary identifier\n",
    "        query = f'''\n",
    "        SELECT \n",
    "            PMCID,\n",
    "            PMID,\n",
    "            * EXCEPT (PMCID, PMID, prompt, full_response, status)\n",
    "        FROM \n",
    "        AI.GENERATE_TABLE(\n",
    "            MODEL `{PROJECT_ID}.{USER_DATASET}.gemini_generation`,\n",
    "            (\n",
    "                SELECT \n",
    "                    name AS PMCID,\n",
    "                    PMID,\n",
    "                    CONCAT(\n",
    "                        \"\"\"{full_prompt_escaped}\"\"\",\n",
    "                        content\n",
    "                    ) AS prompt\n",
    "                FROM `{PUBMED_TABLE}`\n",
    "                WHERE name IN ('{pmcids_str}')\n",
    "            ),\n",
    "            STRUCT(\n",
    "                \"\"\"{schema_single_line}\"\"\" AS output_schema,\n",
    "                8192 AS max_output_tokens,\n",
    "                0 AS temperature,\n",
    "                0.95 AS top_p\n",
    "            )\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        # Execute query\n",
    "        query_execution_start = time.time()\n",
    "        results_df = bq_client.query(query).to_dataframe()\n",
    "        query_execution_time = time.time() - query_execution_start\n",
    "        print(f\"   ‚ö° AI.GENERATE_TABLE query executed in {query_execution_time:.2f} seconds\")\n",
    "        \n",
    "        # Convert to list of dictionaries and preserve article content\n",
    "        processing_start = time.time()\n",
    "        results = []\n",
    "        for _, result_row in results_df.iterrows():\n",
    "            result_dict = result_row.to_dict()\n",
    "            \n",
    "            # Clean up year field if it exists\n",
    "            if 'year' in result_dict:\n",
    "                year_val = result_dict['year']\n",
    "                if year_val in [None, 'NaN', 'nan', 'null', '']:\n",
    "                    result_dict['year'] = ''\n",
    "                elif isinstance(year_val, str):\n",
    "                    # Clean the year string\n",
    "                    result_dict['year'] = year_val.strip()\n",
    "            \n",
    "            # Clean up all INT64 fields (numeric and direct type criteria)\n",
    "            for criterion in criteria:\n",
    "                if criterion['type'] in ['numeric', 'direct'] and criterion['name'] in result_dict:\n",
    "                    field_value = result_dict[criterion['name']]\n",
    "                    # Handle NaN, null, or invalid values\n",
    "                    if pd.isna(field_value) or field_value in [None, 'NaN', 'nan', 'null', '']:\n",
    "                        result_dict[criterion['name']] = 0\n",
    "                    else:\n",
    "                        try:\n",
    "                            # Try to convert to int, default to 0 if it fails\n",
    "                            result_dict[criterion['name']] = int(float(str(field_value)))\n",
    "                        except (ValueError, TypeError):\n",
    "                            print(f\"Warning: Could not convert {criterion['name']} value '{field_value}' to int, defaulting to 0\")\n",
    "                            result_dict[criterion['name']] = 0\n",
    "            \n",
    "            # Find the corresponding content from the original df using PMCID\n",
    "            matching_row = df[df['PMCID'] == result_dict.get('PMCID')]\n",
    "            if not matching_row.empty:\n",
    "                result_dict['content'] = matching_row.iloc[0]['content']\n",
    "                # Keep PMID if available for PubMed links\n",
    "                if 'PMID' in matching_row.columns:\n",
    "                    result_dict['PMID'] = matching_row.iloc[0].get('PMID')\n",
    "            results.append(result_dict)\n",
    "        \n",
    "        total_ai_time = time.time() - ai_start_time\n",
    "        print(f\"   ‚úÖ Total AI.GENERATE_TABLE analysis took {total_ai_time:.2f} seconds\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in AI.GENERATE_TABLE analysis: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    \"\"\"Rough estimate of token count for a text.\"\"\"\n",
    "    # Approximation: 1 token ‚âà 4 characters\n",
    "    return len(text) // 4\n",
    "\n",
    "def format_article_for_analysis(article, idx):\n",
    "    \"\"\"Format a single article for the analysis prompt.\"\"\"\n",
    "    metadata = article.get('metadata', article)\n",
    "    \n",
    "    # Get events found\n",
    "    events_found = metadata.get('actionable_events', 'None')\n",
    "    if isinstance(events_found, str) and events_found:\n",
    "        events_str = events_found\n",
    "    else:\n",
    "        events_str = \"None identified\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "Article {idx}:\n",
    "Title: {metadata.get('title', 'Unknown')}\n",
    "Journal: {metadata.get('journal_title', 'Unknown')} | Year: {metadata.get('year', 'N/A')}\n",
    "Type: {metadata.get('paper_type', 'Unknown')}\n",
    "Score: {article.get('score', 0):.1f}\n",
    "Key Concepts Found: {events_str}\n",
    "PMID: {article.get('pmid', 'N/A')} | PMCID: {article.get('pmcid', 'N/A')}\n",
    "\n",
    "Full Text:\n",
    "{article.get('content', 'No content available')}\n",
    "\"\"\"\n",
    "\n",
    "def create_final_analysis_prompt(case_text, disease, events, selected_articles):\n",
    "    \"\"\"Create the final analysis prompt with full article contents.\"\"\"\n",
    "    \n",
    "    if not selected_articles:\n",
    "        return None\n",
    "    \n",
    "    # Sort articles by score\n",
    "    sorted_articles = sorted(selected_articles, key=lambda x: x.get('score', 0), reverse=True)\n",
    "    \n",
    "    # Format all selected articles\n",
    "    articles_content_parts = []\n",
    "    for idx, article in enumerate(sorted_articles, 1):\n",
    "        articles_content_parts.append(format_article_for_analysis(article, idx))\n",
    "    \n",
    "    # Join all articles with separator\n",
    "    articles_content = (\"\\n\" + \"=\"*80 + \"\\n\").join(articles_content_parts)\n",
    "    \n",
    "    # Fill in the template\n",
    "    filled_prompt = FINAL_ANALYSIS_PROMPT_TEMPLATE.format(\n",
    "        case_description=case_text,\n",
    "        primary_focus=disease,\n",
    "        key_concepts=', '.join(events),\n",
    "        articles_content=articles_content\n",
    "    )\n",
    "    \n",
    "    return filled_prompt\n",
    "\n",
    "def generate_final_analysis_stream(case_text, disease, events, selected_articles, genai_client):\n",
    "    \"\"\"Generate final analysis with streaming response.\"\"\"\n",
    "    \n",
    "    if not selected_articles:\n",
    "        yield \"‚ùå No articles selected. Please select at least one article for analysis.\"\n",
    "        return\n",
    "    \n",
    "    if not genai_client:\n",
    "        yield \"‚ùå Gemini client not initialized. Please complete setup first.\"\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Create the prompt\n",
    "        prompt = create_final_analysis_prompt(case_text, disease, events, selected_articles)\n",
    "        \n",
    "        if not prompt:\n",
    "            yield \"‚ùå Could not create analysis prompt.\"\n",
    "            return\n",
    "        \n",
    "        # Generate content with streaming\n",
    "        config = GenerateContentConfig(\n",
    "            temperature=0.3,  # Slightly higher for more creative synthesis\n",
    "            max_output_tokens=8192,\n",
    "            candidate_count=1,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET)\n",
    "        )\n",
    "        \n",
    "        # First yield to show we're starting\n",
    "        yield \"üîÑ Generating comprehensive analysis...\\n\\n\"\n",
    "        \n",
    "        # Stream the response\n",
    "        try:\n",
    "            response_stream = genai_client.models.generate_content_stream(\n",
    "                model=MODEL_ID,\n",
    "                contents=[prompt],\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            # Accumulate the full response for streaming\n",
    "            accumulated_text = \"\"\n",
    "            \n",
    "            for chunk in response_stream:\n",
    "                if hasattr(chunk, 'candidates') and chunk.candidates:\n",
    "                    for candidate in chunk.candidates:\n",
    "                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):\n",
    "                            for part in candidate.content.parts:\n",
    "                                if hasattr(part, 'text'):\n",
    "                                    accumulated_text += part.text\n",
    "                                    # Yield the accumulated content so far\n",
    "                                    yield accumulated_text\n",
    "            \n",
    "            # If no content was generated\n",
    "            if not accumulated_text:\n",
    "                yield \"‚ùå No analysis was generated. Please try again.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            yield f\"‚ùå Error during analysis generation: {str(e)}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        yield f\"‚ùå Error generating final analysis: {str(e)}\"\n",
    "\n",
    "def setup_bigquery(project, dataset, client, model_endpoint, progress=gr.Progress()):\n",
    "    \"\"\"Setup BigQuery dataset and models with retry logic.\"\"\"\n",
    "    progress(0.8, desc=\"Setting up BigQuery dataset and models (may take a couple minutes if first time)...\")\n",
    "    \n",
    "    # Create dataset if it doesn't exist\n",
    "    try:\n",
    "        client.get_dataset(f\"{project}.{dataset}\")\n",
    "    except:\n",
    "        client.create_dataset(bigquery.Dataset(f\"{project}.{dataset}\"), exists_ok=True)\n",
    "    \n",
    "    # Setup journal impact table\n",
    "    setup_journal_impact_table(client, project, dataset, progress)\n",
    "    \n",
    "    # Create text embedding model\n",
    "    embed_model_query = f\"CREATE MODEL IF NOT EXISTS `{project}.{dataset}.textembed` REMOTE WITH CONNECTION DEFAULT OPTIONS(endpoint='text-embedding-005');\"\n",
    "    \n",
    "    # Create Gemini generation model with dynamic model endpoint\n",
    "    gen_model_query = f\"CREATE OR REPLACE MODEL `{project}.{dataset}.gemini_generation` REMOTE WITH CONNECTION DEFAULT OPTIONS(endpoint='{model_endpoint}');\"\n",
    "    \n",
    "    models_to_create = [\n",
    "        (\"text embedding\", embed_model_query),\n",
    "        (\"Gemini generation\", gen_model_query)\n",
    "    ]\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_delays = [5, 10, 15]\n",
    "    \n",
    "    for model_name, model_query in models_to_create:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"Creating BigQuery {model_name} model (attempt {attempt + 1}/{max_retries})...\")\n",
    "                client.query(model_query).result()\n",
    "                print(f\"Successfully created {model_name} model for {project}.{dataset}\")\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                print(f\"Attempt {attempt + 1} failed for {model_name}: {error_msg}\")\n",
    "                \n",
    "                # Check if it's a job execution error that might be timing-related\n",
    "                if \"internal error during execution\" in error_msg.lower() and attempt < max_retries - 1:\n",
    "                    delay = retry_delays[attempt]\n",
    "                    print(f\"This appears to be a timing issue. Waiting {delay} seconds before retry...\")\n",
    "                    time.sleep(delay)\n",
    "                elif attempt < max_retries - 1:\n",
    "                    # For other errors, also retry but with shorter delay\n",
    "                    delay = retry_delays[attempt] // 2\n",
    "                    print(f\"Waiting {delay} seconds before retry...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    # All retries exhausted\n",
    "                    print(f\"All {max_retries} attempts failed for {model_name}.\")\n",
    "                    raise Exception(f\"Failed to create {model_name} model after {max_retries} attempts. Last error: {error_msg}\")\n",
    "    \n",
    "    return f\"‚úÖ BigQuery setup complete for {project}.{dataset}\"\n",
    "\n",
    "# --- Gradio App Logic ---\n",
    "def get_initial_projects():\n",
    "    \"\"\"Get the list of projects for the dropdown.\"\"\"\n",
    "    projects = list_projects()\n",
    "    if not projects:\n",
    "        # Provide option to manually enter project ID\n",
    "        return gr.update(choices=[\"[Enter Project ID Manually]\"], value=\"[Enter Project ID Manually]\"), \"‚ö†Ô∏è Could not list projects automatically. You can either fix the authentication issue (see console) or enter your project ID manually in the field below.\"\n",
    "    choices = [f\"{p['name']} ({p['id']})\" for p in projects]\n",
    "    return gr.update(choices=choices, value=choices[0] if choices else None), f\"‚úÖ Found {len(projects)} projects. Select a project and click Proceed.\"\n",
    "\n",
    "def proceed_with_project(project_selection, model_selection, thinking_budget, progress=gr.Progress()):\n",
    "    \"\"\"Check and set up the selected project, then move to the next tab.\"\"\"\n",
    "    global genai_client, bq_client, journal_impact_dict, PROJECT_ID, LOCATION, USER_DATASET, MODEL_ID, THINKING_BUDGET\n",
    "    if not project_selection:\n",
    "        return \"‚ùå Please select a project first.\", gr.update(interactive=False), gr.update()\n",
    "\n",
    "    project_id = project_selection.split('(')[-1].rstrip(')')\n",
    "    PROJECT_ID = project_id\n",
    "    \n",
    "    # Update global model settings\n",
    "    MODEL_ID = MODEL_OPTIONS[model_selection]\n",
    "    THINKING_BUDGET = thinking_budget\n",
    "    \n",
    "    # Clear any existing project environment variable\n",
    "    if 'GOOGLE_CLOUD_PROJECT' in os.environ:\n",
    "        del os.environ['GOOGLE_CLOUD_PROJECT']\n",
    "    \n",
    "    # Set the new project ID\n",
    "    os.environ['GOOGLE_CLOUD_PROJECT'] = project_id\n",
    "\n",
    "    try:\n",
    "        progress(0.1, desc=\"Checking billing status...\")\n",
    "        if not check_billing_enabled(project_id):\n",
    "            # Return special status to trigger billing setup\n",
    "            return \"billing_needed\", gr.update(interactive=False), gr.update()\n",
    "\n",
    "        progress(0.2, desc=\"Checking required APIs...\")\n",
    "        enabled_apis = list_enabled_apis(project_id)\n",
    "        missing_apis = [api for api in REQUIRED_APIS if api not in enabled_apis]\n",
    "        if missing_apis:\n",
    "            enable_apis(project_id, missing_apis, progress)\n",
    "\n",
    "        # Use the shared setup logic with model endpoint\n",
    "        genai_client, bq_client, journal_impact_dict = setup_project(PROJECT_ID, LOCATION, USER_DATASET, MODEL_ID, progress)\n",
    "\n",
    "        status = f\"‚úÖ Setup complete for {PROJECT_ID} with model {model_selection}! You can now analyze a case.\"\n",
    "        return status, gr.update(interactive=True), gr.update(selected=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\", gr.update(interactive=False), gr.update()\n",
    "\n",
    "css = \"\"\"\n",
    ".gradio-container { font-family: 'Google Sans', sans-serif; }\n",
    "label, .label-wrap, .gradio-label { \n",
    "    background-color: transparent !important; \n",
    "    border: none !important; \n",
    "    box-shadow: none !important; \n",
    "    padding: 0 !important; \n",
    "}\n",
    ".label-wrap {\n",
    "    border: none !important;\n",
    "}\n",
    ".type-info {\n",
    "    font-size: 0.9em;\n",
    "    color: #666;\n",
    "}\n",
    ".extraction-result {\n",
    "    background-color: #f8f9fa;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    margin: 10px 0;\n",
    "    font-family: monospace;\n",
    "    white-space: pre-wrap;\n",
    "    color: #212529 !important;  /* Ensure dark text */\n",
    "}\n",
    ".extraction-result * {\n",
    "    color: #212529 !important;  /* Ensure all child elements have dark text */\n",
    "}\n",
    ".article-card {\n",
    "    margin: 20px 0;\n",
    "    padding: 20px;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    background-color: #e8f4f8;  /* Light blue background */\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "}\n",
    ".score-breakdown-box {\n",
    "    margin: 15px 0;\n",
    "    padding: 15px;\n",
    "    background-color: #d1ecf1;  /* Slightly darker blue */\n",
    "    border-radius: 5px;\n",
    "    border: 1px solid #bee5eb;\n",
    "}\n",
    ".article-content-box {\n",
    "    margin-top: 10px;\n",
    "    padding: 15px;\n",
    "    background-color: #ffffff;  /* White background for article text */\n",
    "    border-radius: 5px;\n",
    "    max-height: 600px;\n",
    "    overflow-y: auto;\n",
    "    border: 1px solid #dee2e6;\n",
    "}\n",
    ".article-content-box pre {\n",
    "    white-space: pre-wrap;\n",
    "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "    margin: 0;\n",
    "    font-size: 14px;\n",
    "    line-height: 1.6;\n",
    "    color: #212529 !important;  /* Black text for readability */\n",
    "}\n",
    ".final-analysis-display {\n",
    "    background-color: #ffffff !important;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    padding: 30px;\n",
    "    margin: 20px 0;\n",
    "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "    line-height: 1.8;\n",
    "    color: #212529 !important;\n",
    "    max-height: 800px;\n",
    "    overflow-y: auto;\n",
    "}\n",
    ".final-analysis-display * {\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display h2 {\n",
    "    color: #0066cc !important;\n",
    "    border-bottom: 2px solid #0066cc;\n",
    "    padding-bottom: 10px;\n",
    "    margin-top: 30px;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    ".final-analysis-display h3 {\n",
    "    color: #333 !important;\n",
    "    margin-top: 25px;\n",
    "    margin-bottom: 15px;\n",
    "}\n",
    ".final-analysis-display table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse;\n",
    "    margin: 20px 0;\n",
    "    background-color: #fff !important;\n",
    "    box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
    "}\n",
    ".final-analysis-display th {\n",
    "    background-color: #f8f9fa !important;\n",
    "    border: 1px solid #dee2e6;\n",
    "    padding: 12px;\n",
    "    text-align: left;\n",
    "    font-weight: bold;\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display td {\n",
    "    border: 1px solid #dee2e6;\n",
    "    padding: 12px;\n",
    "    vertical-align: top;\n",
    "    color: #212529 !important;\n",
    "    word-wrap: break-word;\n",
    "    word-break: break-word;\n",
    "    max-width: 300px;\n",
    "}\n",
    ".final-analysis-display td * {\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display a {\n",
    "    color: #0066cc !important;\n",
    "    text-decoration: none;\n",
    "}\n",
    ".final-analysis-display a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    ".final-analysis-display ul, .final-analysis-display ol {\n",
    "    margin: 10px 0;\n",
    "    padding-left: 30px;\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display li {\n",
    "    margin: 5px 0;\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display p {\n",
    "    color: #212529 !important;\n",
    "}\n",
    ".final-analysis-display span {\n",
    "    color: #212529 !important;\n",
    "}\n",
    "\"\"\"\n",
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"sky\"), css=css) as demo:\n",
    "    gr.Markdown(\"# üè• PubMed Literature Analysis\")\n",
    "    app_state = gr.State({})\n",
    "\n",
    "    with gr.Tabs() as tabs:\n",
    "        with gr.TabItem(\"Get Started\", id=0):\n",
    "            gr.Markdown(\"## Welcome to the PubMed Literature Analysis Tool\")\n",
    "            gr.Markdown(\"This tool helps you analyze medical cases using PubMed literature with BigQuery vector search and Gemini. Get started by setting up your Google Cloud project.\")\n",
    "            gr.Markdown(\"\"\"‚ö†Ô∏è **Important Notice: Demonstration Tool**\\n\\nThis PubMed literature analysis tool is a **DEMONSTRATION** showcasing AI-powered research capabilities.\\n\\n- For **research and educational purposes only**\\n- **NOT** intended for treatment planning or clinical decisions\\n- All AI-generated analyses should be verified against primary sources\\n- Results may contain inaccuracies or limitations\\n- Users are responsible for appropriate use within research contexts\\n\\nBy proceeding, you acknowledge these limitations and agree to use this tool responsibly for research purposes only.\\n\"\"\")\n",
    "            \n",
    "            start_button = gr.Button(\"Get Started\", variant=\"primary\")\n",
    "\n",
    "        with gr.TabItem(\"1. Setup\", id=1):\n",
    "            status_output = gr.Markdown(value=\"Loading projects...\")\n",
    "            with gr.Row():\n",
    "                project_dropdown = gr.Dropdown(label=\"Select Google Cloud Project\", interactive=True)\n",
    "                create_project_btn = gr.Button(\"Create New Project\")\n",
    "\n",
    "            with gr.Column(visible=False) as create_project_box:\n",
    "                gr.Markdown(\"### Create New Google Cloud Project\")\n",
    "                new_project_id_input = gr.Textbox(label=\"New Project ID\", placeholder=\"e.g., pubmed-analysis-123\")\n",
    "                billing_account_dropdown = gr.Dropdown(label=\"Select Billing Account\")\n",
    "                billing_link_message = gr.Markdown(visible=False)\n",
    "                create_project_submit_btn = gr.Button(\"Create and Select Project\", variant=\"primary\")\n",
    "                cancel_create_project_btn = gr.Button(\"Cancel\")\n",
    "\n",
    "            with gr.Column(visible=False) as billing_setup_box:\n",
    "                gr.Markdown(\"### üí≥ Billing Setup Required\")\n",
    "                gr.Markdown(\"This project needs a billing account to use Google Cloud services.\")\n",
    "                billing_setup_dropdown = gr.Dropdown(label=\"Select Billing Account\")\n",
    "                billing_setup_message = gr.Markdown(visible=False)\n",
    "                link_billing_btn = gr.Button(\"Link Billing Account\", variant=\"primary\")\n",
    "                billing_status = gr.Markdown()\n",
    "\n",
    "            with gr.Column() as setup_details_box:\n",
    "                # Model Configuration Section\n",
    "                gr.Markdown(\"### ü§ñ Model Configuration\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    model_dropdown = gr.Dropdown(\n",
    "                        label=\"Select Model\",\n",
    "                        choices=list(MODEL_OPTIONS.keys()),\n",
    "                        value=\"Gemini 2.5 Flash (Default)\",\n",
    "                        interactive=True,\n",
    "                        info=\"Choose the Gemini model to use for analysis\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    thinking_budget_slider = gr.Slider(\n",
    "                        label=\"Thinking Budget\",\n",
    "                        minimum=0,\n",
    "                        maximum=24576,\n",
    "                        value=0,\n",
    "                        step=1,\n",
    "                        interactive=True,\n",
    "                        info=\"Set the thinking budget for model responses (0 = default)\"\n",
    "                    )\n",
    "                \n",
    "                gr.Markdown(\"---\")\n",
    "                proceed_btn = gr.Button(\"Proceed\", variant=\"primary\")\n",
    "\n",
    "        with gr.TabItem(\"2. Case\", id=2):\n",
    "            # Add header row with example button\n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"## Patient Case Notes\")\n",
    "                load_example_btn = gr.Button(\"Load Example\", size=\"sm\", scale=0)\n",
    "            \n",
    "            # Empty case input by default\n",
    "            case_input = gr.Textbox(\n",
    "                label=\"\", \n",
    "                value=\"\",  # Empty instead of SAMPLE_CASE\n",
    "                lines=10,\n",
    "                placeholder=\"Enter patient case details here...\"\n",
    "            )\n",
    "            \n",
    "            # Extract Information section\n",
    "            gr.Markdown(\"---\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                # Info text inline\n",
    "                gr.Markdown(\"#### Extract Information <span style='color: #666; font-size: 0.85em; font-weight: normal; margin-left: 10px;'>This will help the BigQuery vector search be more refined</span>\")\n",
    "                \n",
    "                # Prompt input fields\n",
    "                disease_prompt_input = gr.Textbox(\n",
    "                    label=\"Disease Extraction Prompt\",\n",
    "                    value=\"\",\n",
    "                    lines=5,\n",
    "                    placeholder=\"Enter prompt for disease extraction...\"\n",
    "                )\n",
    "                \n",
    "                events_prompt_input = gr.Textbox(\n",
    "                    label=\"Events Extraction Prompt\", \n",
    "                    value=\"\",\n",
    "                    lines=5,\n",
    "                    placeholder=\"Enter prompt for actionable events extraction...\"\n",
    "                )\n",
    "                \n",
    "                # Extract button\n",
    "                extract_btn = gr.Button(\"Extract\", variant=\"secondary\")\n",
    "                \n",
    "                # Loading indicator\n",
    "                extraction_loading = gr.Markdown(\"üîÑ Extracting information...\", visible=False)\n",
    "                \n",
    "                # Extraction results box\n",
    "                with gr.Column(visible=False) as extraction_box:\n",
    "                    gr.Markdown(\"### Extracted Information\")\n",
    "                    gr.Markdown(\"*You can edit the extracted values below before proceeding with the analysis.*\")\n",
    "                    \n",
    "                    # Editable fields\n",
    "                    with gr.Row():\n",
    "                        disease_edit = gr.Textbox(\n",
    "                            label=\"Disease\",\n",
    "                            value=\"\",\n",
    "                            lines=1,\n",
    "                            interactive=True,\n",
    "                            elem_id=\"disease_edit\"\n",
    "                        )\n",
    "                        reset_disease_btn = gr.Button(\"Reset\", size=\"sm\", scale=0)\n",
    "                    \n",
    "                    events_edit = gr.Textbox(\n",
    "                        label=\"Actionable Events\",\n",
    "                        value=\"\",\n",
    "                        lines=3,\n",
    "                        interactive=True,\n",
    "                        elem_id=\"events_edit\",\n",
    "                        info=\"One event per line or comma-separated\"\n",
    "                    )\n",
    "                    reset_events_btn = gr.Button(\"Reset to AI suggestion\", size=\"sm\")\n",
    "                    \n",
    "                    # Original AI extraction display (for reference)\n",
    "                    with gr.Accordion(\"View Original AI Extraction\", open=False):\n",
    "                        ai_extraction_display = gr.Markdown(\"\")\n",
    "                \n",
    "                # Store extraction state\n",
    "                extraction_state = gr.State({\"extracted\": False, \"disease\": \"\", \"events\": \"\"})\n",
    "            \n",
    "            # Hidden slider - keeps default value of 10\n",
    "            num_articles_slider = gr.Slider(\n",
    "                5, 50, 10, \n",
    "                step=1, \n",
    "                label=\"Number of Articles to Analyze\",\n",
    "                visible=False  # Hide the slider\n",
    "            )\n",
    "            \n",
    "            # Changed button text and purpose\n",
    "            proceed_to_persona_btn = gr.Button(\"Proceed\", variant=\"primary\", interactive=False)\n",
    "            case_status = gr.Markdown()\n",
    "\n",
    "        with gr.TabItem(\"3. Persona\", id=3):\n",
    "            gr.Markdown(\"## Customize Your Analysis Persona\")\n",
    "            gr.Markdown(\"*Define your research perspective and customize how articles will be scored for relevance.*\")\n",
    "            \n",
    "            # Persona Section (Top Box)\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Analysis Persona\")\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=4):\n",
    "                        persona_text = gr.Textbox(\n",
    "                            label=\"\",\n",
    "                            value=\"You are a medical researcher analyzing literature for clinical relevance and treatment insights.\",\n",
    "                            lines=4,\n",
    "                            placeholder=\"Describe your research perspective and goals...\"\n",
    "                        )\n",
    "                    with gr.Column(scale=1):\n",
    "                        load_persona_btn = gr.Button(\"Load Example\", size=\"sm\")\n",
    "                        \n",
    "                # Example personas (hidden, for dropdown)\n",
    "                example_personas = gr.State({\n",
    "                    \"Clinical Researcher\": \"You are a pediatric oncologist focused on finding the latest treatment protocols and clinical trial results for childhood cancers. Prioritize evidence-based therapies with proven efficacy.\",\n",
    "                    \"Pharmaceutical Developer\": \"You are a pharmaceutical researcher looking for novel drug targets and biomarkers with strong preclinical and clinical evidence. Focus on mechanistic insights and translational potential.\",\n",
    "                    \"Patient Advocate\": \"You are evaluating treatment options from a patient perspective, prioritizing safety profiles, quality of life outcomes, and accessibility of treatments.\",\n",
    "                    \"Basic Scientist\": \"You are a molecular biologist interested in understanding disease mechanisms at the cellular and molecular level. Focus on novel pathways, genetic factors, and potential therapeutic targets.\"\n",
    "                })\n",
    "            \n",
    "            gr.Markdown(\"---\")\n",
    "            \n",
    "            # Scoring Criteria Section (Bottom Box)\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Article Scoring Criteria\")\n",
    "                gr.Markdown(\"*Adjust weights to prioritize what matters most for your analysis. Articles will be scored based on these criteria.*\")\n",
    "                \n",
    "                # We'll store criteria in state\n",
    "                criteria_state = gr.State([])\n",
    "                \n",
    "                # Add controls\n",
    "                with gr.Row():\n",
    "                    add_criterion_btn = gr.Button(\"‚ûï Add New Criterion\", size=\"sm\")\n",
    "                    reset_criteria_btn = gr.Button(\"üîÑ Reset to Defaults\", size=\"sm\")\n",
    "                    \n",
    "                # Total weight display\n",
    "                total_weight_display = gr.Markdown(\"**Total Weight:** 0\")\n",
    "                \n",
    "                # Container for criteria - pre-create 20 slots\n",
    "                criterion_rows = []\n",
    "                criterion_descriptions = []\n",
    "                criterion_type_infos = []\n",
    "                criterion_sliders = []\n",
    "                criterion_delete_btns = []\n",
    "                \n",
    "                with gr.Column() as criteria_container:\n",
    "                    for i in range(20):  # Create 20 slots\n",
    "                        with gr.Row(visible=False) as row:\n",
    "                            with gr.Column(scale=3):\n",
    "                                desc = gr.Markdown(\"\")\n",
    "                                type_info = gr.Markdown(\"\", elem_classes=\"type-info\")\n",
    "                            \n",
    "                            with gr.Column(scale=2):\n",
    "                                slider = gr.Slider(\n",
    "                                    minimum=0,\n",
    "                                    maximum=100,\n",
    "                                    value=0,\n",
    "                                    label=\"Weight\",\n",
    "                                    step=1\n",
    "                                )\n",
    "                            \n",
    "                            with gr.Column(scale=1):\n",
    "                                delete_btn = gr.Button(\"üóëÔ∏è Delete\", variant=\"stop\", size=\"sm\")\n",
    "                        \n",
    "                        criterion_rows.append(row)\n",
    "                        criterion_descriptions.append(desc)\n",
    "                        criterion_type_infos.append(type_info)\n",
    "                        criterion_sliders.append(slider)\n",
    "                        criterion_delete_btns.append(delete_btn)\n",
    "                \n",
    "                # Add criterion dialog\n",
    "                with gr.Column(visible=False) as add_criterion_dialog:\n",
    "                    gr.Markdown(\"### Add New Scoring Criterion\")\n",
    "                    new_criterion_description = gr.Textbox(\n",
    "                        label=\"Description\",\n",
    "                        placeholder=\"e.g., Does the article include safety data?\",\n",
    "                        lines=2\n",
    "                    )\n",
    "                    new_criterion_type = gr.Dropdown(\n",
    "                        label=\"Type\",\n",
    "                        choices=[\"boolean\", \"numeric\", \"direct\"],\n",
    "                        value=\"boolean\",\n",
    "                        info=\"Boolean: Yes/No criteria | Numeric: Multiplies value by weight | Direct: Uses value as-is\"\n",
    "                    )\n",
    "                    new_criterion_weight = gr.Slider(\n",
    "                        label=\"Weight\",\n",
    "                        minimum=0,\n",
    "                        maximum=100,\n",
    "                        value=10,\n",
    "                        step=1\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        confirm_add_btn = gr.Button(\"Add\", variant=\"primary\", size=\"sm\")\n",
    "                        cancel_add_btn = gr.Button(\"Cancel\", size=\"sm\")\n",
    "                \n",
    "            analyze_btn = gr.Button(\"Retrieve and analyze articles\", variant=\"primary\", interactive=True)\n",
    "            analysis_status = gr.Markdown()\n",
    "\n",
    "        with gr.TabItem(\"4. Results\", id=4):\n",
    "            # Analysis configuration section\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Analysis Configuration\")\n",
    "                with gr.Row():\n",
    "                    default_articles_input = gr.Number(\n",
    "                        label=\"Default Articles to Retrieve\",\n",
    "                        value=5,\n",
    "                        minimum=1,\n",
    "                        maximum=50,\n",
    "                        step=1,\n",
    "                        info=\"Initial number of articles to retrieve from PubMed\"\n",
    "                    )\n",
    "                    min_articles_per_event = gr.Number(\n",
    "                        label=\"Minimum Articles per Event\",\n",
    "                        value=3,\n",
    "                        minimum=1,\n",
    "                        maximum=10,\n",
    "                        step=1,\n",
    "                        info=\"Minimum number of articles required for each actionable event\"\n",
    "                    )\n",
    "                start_analysis_btn = gr.Button(\"Start Analysis\", variant=\"primary\")\n",
    "                \n",
    "                # Configuration state\n",
    "                analysis_config = gr.State({\n",
    "                    \"default_articles\": 5,\n",
    "                    \"min_per_event\": 3,\n",
    "                    \"max_articles\": 50\n",
    "                })\n",
    "            \n",
    "            gr.Markdown(\"---\")\n",
    "            \n",
    "            # Progress tracking components\n",
    "            with gr.Row():\n",
    "                analysis_progress = gr.Markdown(\"Configure settings above and click 'Start Analysis' to begin.\")\n",
    "                stop_analysis_btn = gr.Button(\"Stop Analysis\", variant=\"stop\", visible=False)\n",
    "            \n",
    "            # Event coverage display\n",
    "            event_coverage_display = gr.Markdown(visible=False)\n",
    "            \n",
    "            # Live results display - hidden as it's redundant\n",
    "            live_results_df = gr.DataFrame(\n",
    "                label=\"Article Analysis Results (Live)\",\n",
    "                headers=[\"Score\", \"Title\", \"Journal\", \"Year\", \"Status\"],\n",
    "                interactive=False,\n",
    "                visible=False  # Hide the redundant table\n",
    "            )\n",
    "            \n",
    "            # Detailed analysis display - expanded by default\n",
    "            with gr.Accordion(\"Detailed Analysis\", open=True) as analysis_accordion:\n",
    "                detailed_analysis_html = gr.HTML()\n",
    "            \n",
    "            # State to track results\n",
    "            results_state = gr.State([])\n",
    "            analysis_active = gr.State(False)\n",
    "            \n",
    "            # Final Analysis Button - appears after analysis (replaces summary)\n",
    "            with gr.Row():\n",
    "                # Empty column for centering\n",
    "                gr.Column()\n",
    "                with gr.Column(scale=2):\n",
    "                    final_analysis_btn = gr.Button(\"Proceed to Final Analysis\", variant=\"primary\", visible=False)\n",
    "                gr.Column()\n",
    "\n",
    "        with gr.TabItem(\"5. Final Analysis\", id=5):\n",
    "            gr.Markdown(\"## Final Analysis\")\n",
    "            gr.Markdown(\"*Select articles to include in the comprehensive synthesis, then generate the final analysis.*\")\n",
    "            \n",
    "            # Article selection section\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Select Articles for Analysis\")\n",
    "                \n",
    "                # Selection controls\n",
    "                with gr.Row():\n",
    "                    select_all_btn = gr.Button(\"Select All\", size=\"sm\")\n",
    "                    deselect_all_btn = gr.Button(\"Deselect All\", size=\"sm\")\n",
    "                    selected_count = gr.Markdown(\"0 articles selected\")\n",
    "                    token_estimate = gr.Markdown(\"Estimated tokens: 0\")\n",
    "                \n",
    "                # Article checkboxes (will be populated dynamically)\n",
    "                article_selections = gr.CheckboxGroup(\n",
    "                    label=\"\",\n",
    "                    choices=[],\n",
    "                    value=[],\n",
    "                    elem_id=\"article_selections\"\n",
    "                )\n",
    "            \n",
    "            gr.Markdown(\"---\")\n",
    "            \n",
    "            # Analysis Prompt Section\n",
    "            with gr.Column():\n",
    "                with gr.Accordion(\"üìù Customize Analysis Prompt\", open=False):\n",
    "                    gr.Markdown(\"*Edit the prompt template below to customize how the final analysis is generated. Use the placeholders `{case_description}`, `{primary_focus}`, `{key_concepts}`, and `{articles_content}` to include dynamic content.*\")\n",
    "                    \n",
    "                    analysis_prompt_input = gr.Textbox(\n",
    "                        label=\"Analysis Prompt Template\",\n",
    "                        value=FINAL_ANALYSIS_PROMPT_TEMPLATE,\n",
    "                        lines=20,\n",
    "                        placeholder=\"Enter your custom analysis prompt template...\",\n",
    "                        elem_id=\"analysis_prompt_input\"\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        reset_prompt_btn = gr.Button(\"Reset to Default\", size=\"sm\")\n",
    "                        load_example_prompt_btn = gr.Button(\"Load Example\", size=\"sm\")\n",
    "                \n",
    "                # Generate button\n",
    "                generate_final_btn = gr.Button(\n",
    "                    \"Generate Final Analysis\", \n",
    "                    variant=\"primary\", \n",
    "                    interactive=False\n",
    "                )\n",
    "            \n",
    "            gr.Markdown(\"---\")\n",
    "            \n",
    "            # Analysis display section\n",
    "            with gr.Column():\n",
    "                final_analysis_progress = gr.Markdown(\"\")\n",
    "                final_analysis_display = gr.Markdown(\n",
    "                    \"\", \n",
    "                    elem_classes=\"final-analysis-display\"\n",
    "                )\n",
    "            \n",
    "            # State to track selected articles\n",
    "            selected_articles_state = gr.State([])\n",
    "            \n",
    "            # Example prompts state\n",
    "            example_prompts = gr.State({\n",
    "                \"Clinical Focus\": \"\"\"You are a clinical researcher synthesizing findings for medical practice.\n",
    "\n",
    "CASE: {case_description}\n",
    "DISEASE: {primary_focus}\n",
    "KEY FACTORS: {key_concepts}\n",
    "\n",
    "ANALYZED ARTICLES:\n",
    "{articles_content}\n",
    "\n",
    "Please provide a clinical synthesis with these sections:\n",
    "\n",
    "## Clinical Summary: {primary_focus}\n",
    "\n",
    "### Key Clinical Findings\n",
    "- Summarize the most clinically relevant findings\n",
    "- Focus on treatment efficacy and safety\n",
    "- Highlight patient outcomes\n",
    "\n",
    "### Treatment Recommendations\n",
    "| Treatment | Evidence Level | Success Rate | Side Effects |\n",
    "|-----------|---------------|--------------|--------------|\n",
    "[Analyze treatments from the articles]\n",
    "\n",
    "### Clinical Pearls\n",
    "- List key takeaways for clinicians\n",
    "- Include dosing considerations\n",
    "- Note any contraindications\n",
    "\n",
    "### Future Directions\n",
    "- Identify gaps in clinical knowledge\n",
    "- Suggest areas for clinical trials\n",
    "\"\"\",\n",
    "                \"Research Focus\": FINAL_ANALYSIS_PROMPT_TEMPLATE  # Default template\n",
    "            })\n",
    "\n",
    "    # --- Event Handlers for UI ---\n",
    "    def show_create_project_form():\n",
    "        accounts = list_billing_accounts()\n",
    "        return gr.update(visible=True), gr.update(choices=accounts, value=accounts[0] if accounts else None), gr.update(visible=False)\n",
    "\n",
    "    def hide_create_project_form():\n",
    "        return gr.update(visible=False), gr.update(visible=True)\n",
    "\n",
    "    def handle_billing_selection(billing_account):\n",
    "        if billing_account is None:\n",
    "            # Don't change anything when None is selected\n",
    "            return gr.update(), gr.update()\n",
    "        if billing_account == CREATE_BILLING_ACCOUNT_OPTION:\n",
    "            # Clear the dropdown selection and return a status message\n",
    "            status_msg = f\"\\n\\nüìã **To create a billing account:**\\n\\n1. Open this link in your browser: {CREATE_BILLING_ACCOUNT_URL}\\n2. Complete the billing account setup\\n3. Restart the Gradio app and select your new billing account from the dropdown\\n\\n\"\n",
    "            return gr.update(value=None), gr.update(value=status_msg, visible=True)\n",
    "        # Valid billing account selected, hide the message\n",
    "        return gr.update(), gr.update(visible=False)\n",
    "\n",
    "    def handle_project_creation(project_id, billing_account, model_dropdown, thinking_budget_slider, progress=gr.Progress()):\n",
    "        # Get the model endpoint from the dropdown selection\n",
    "        model_endpoint = MODEL_OPTIONS[model_dropdown]\n",
    "        status, new_project_selection = create_new_project(project_id, billing_account, model_endpoint, thinking_budget_slider, progress)\n",
    "        if new_project_selection:\n",
    "            projects = list_projects()\n",
    "            choices = [f\"{p['name']} ({p['id']})\" for p in projects]\n",
    "            return gr.update(visible=False), gr.update(visible=True), gr.update(choices=choices, value=new_project_selection), status, gr.update(selected=2)\n",
    "        return gr.update(), gr.update(), gr.update(), status, gr.update()\n",
    "\n",
    "    # Tab Switching\n",
    "    start_button.click(lambda: gr.update(selected=1), None, tabs)\n",
    "\n",
    "    # Setup Tab Interactions\n",
    "    create_project_btn.click(show_create_project_form, outputs=[create_project_box, billing_account_dropdown, setup_details_box])\n",
    "    cancel_create_project_btn.click(hide_create_project_form, outputs=[create_project_box, setup_details_box])\n",
    "    billing_account_dropdown.change(handle_billing_selection, inputs=[billing_account_dropdown], outputs=[billing_account_dropdown, billing_link_message])\n",
    "    create_project_submit_btn.click(\n",
    "        handle_project_creation, \n",
    "        inputs=[new_project_id_input, billing_account_dropdown, model_dropdown, thinking_budget_slider], \n",
    "        outputs=[create_project_box, setup_details_box, project_dropdown, status_output, tabs]\n",
    "    )\n",
    "    def handle_billing_setup_selection(billing_account):\n",
    "        \"\"\"Handle billing account selection in the billing setup box.\"\"\"\n",
    "        if billing_account is None:\n",
    "            # Don't change anything when None is selected\n",
    "            return gr.update(), gr.update()\n",
    "        if billing_account == CREATE_BILLING_ACCOUNT_OPTION:\n",
    "            # Clear the dropdown selection and return a status message\n",
    "            status_msg = f\"\\n\\nüìã **To create a billing account:**\\n\\n1. Open this link in your browser: {CREATE_BILLING_ACCOUNT_URL}\\n2. Complete the billing account setup\\n3. Restart the Gradio app and select your new billing account from the dropdown\\n\\n\"\n",
    "            return gr.update(value=None), gr.update(value=status_msg, visible=True)\n",
    "        # Valid billing account selected, hide the message\n",
    "        return gr.update(), gr.update(visible=False)\n",
    "\n",
    "    def handle_link_billing(billing_account, project_dropdown, model_dropdown, thinking_budget_slider, progress=gr.Progress()):\n",
    "        \"\"\"Handle linking billing account to the project.\"\"\"\n",
    "        if not billing_account or billing_account == CREATE_BILLING_ACCOUNT_OPTION:\n",
    "            return \"‚ùå Please select a valid billing account.\", gr.update(visible=True), gr.update(visible=False)\n",
    "        \n",
    "        project_id = project_dropdown.split('(')[-1].rstrip(')')\n",
    "        progress(0.1, desc=\"Linking billing account...\")\n",
    "        \n",
    "        success, message = link_billing_to_project(project_id, billing_account)\n",
    "        if success:\n",
    "            progress(0.3, desc=\"Billing linked! Continuing setup...\")\n",
    "            # After successful billing link, continue with the normal setup with model settings\n",
    "            status, analyze_btn_update, tabs_update = proceed_with_project(project_dropdown, model_dropdown, thinking_budget_slider, progress)\n",
    "            # Return appropriate updates for this function's outputs\n",
    "            # The .then() chains will handle the analyze button and tabs updates based on the status message\n",
    "            return status, gr.update(visible=False), gr.update(visible=True)\n",
    "        else:\n",
    "            return message, gr.update(visible=True), gr.update(visible=False)\n",
    "\n",
    "    # State to track if we need billing setup\n",
    "    needs_billing_setup = gr.State(False)\n",
    "    \n",
    "    # Modified proceed button click handler\n",
    "    def handle_proceed_click(project_dropdown, model_dropdown, thinking_budget_slider, progress=gr.Progress()):\n",
    "        \"\"\"Handle the proceed button click.\"\"\"\n",
    "        status, analyze_btn_update, tabs_update = proceed_with_project(project_dropdown, model_dropdown, thinking_budget_slider, progress)\n",
    "        \n",
    "        if status == \"billing_needed\":\n",
    "            # Show billing setup box and populate dropdown\n",
    "            accounts = list_billing_accounts()\n",
    "            return (\n",
    "                \"‚ùå Billing is not enabled for this project. Please set up billing to continue.\",\n",
    "                gr.update(interactive=False),  # analyze_btn\n",
    "                gr.update(),  # tabs (no change)\n",
    "                gr.update(visible=True),  # billing_setup_box\n",
    "                gr.update(visible=False),  # setup_details_box\n",
    "                gr.update(choices=accounts, value=accounts[0] if accounts else None),  # billing_setup_dropdown\n",
    "                True  # needs_billing_setup state\n",
    "            )\n",
    "        else:\n",
    "            # Normal flow\n",
    "            return (\n",
    "                status,\n",
    "                analyze_btn_update,\n",
    "                tabs_update,\n",
    "                gr.update(visible=False),  # billing_setup_box\n",
    "                gr.update(visible=True),  # setup_details_box\n",
    "                gr.update(),  # billing_setup_dropdown (no change)\n",
    "                False  # needs_billing_setup state\n",
    "            )\n",
    "    \n",
    "    proceed_btn.click(\n",
    "        handle_proceed_click, \n",
    "        inputs=[project_dropdown, model_dropdown, thinking_budget_slider], \n",
    "        outputs=[status_output, analyze_btn, tabs, billing_setup_box, setup_details_box, billing_setup_dropdown, needs_billing_setup]\n",
    "    )\n",
    "\n",
    "    # Billing setup handlers\n",
    "    billing_setup_dropdown.change(\n",
    "        handle_billing_setup_selection, \n",
    "        inputs=[billing_setup_dropdown], \n",
    "        outputs=[billing_setup_dropdown, billing_setup_message]\n",
    "    )\n",
    "    \n",
    "    # Helper functions for the .then() chains\n",
    "    def update_analyze_btn_based_on_status(status_markdown):\n",
    "        \"\"\"Update analyze button based on the status message.\"\"\"\n",
    "        # Extract the actual text value from the Markdown component data\n",
    "        if isinstance(status_markdown, dict) and 'value' in status_markdown:\n",
    "            status_text = status_markdown['value']\n",
    "        elif isinstance(status_markdown, str):\n",
    "            status_text = status_markdown\n",
    "        else:\n",
    "            status_text = str(status_markdown)\n",
    "        \n",
    "        return gr.update(interactive=status_text.startswith(\"‚úÖ\"))\n",
    "    \n",
    "    def update_tabs_based_on_status(status_markdown):\n",
    "        \"\"\"Update tabs based on the status message.\"\"\"\n",
    "        # Extract the actual text value from the Markdown component data\n",
    "        if isinstance(status_markdown, dict) and 'value' in status_markdown:\n",
    "            status_text = status_markdown['value']\n",
    "        elif isinstance(status_markdown, str):\n",
    "            status_text = status_markdown\n",
    "        else:\n",
    "            status_text = str(status_markdown)\n",
    "        \n",
    "        if status_text.startswith(\"‚úÖ\"):\n",
    "            return gr.update(selected=2)\n",
    "        else:\n",
    "            return gr.update()\n",
    "    \n",
    "    link_billing_output = link_billing_btn.click(\n",
    "        handle_link_billing,\n",
    "        inputs=[billing_setup_dropdown, project_dropdown, model_dropdown, thinking_budget_slider],\n",
    "        outputs=[status_output, billing_setup_box, setup_details_box]\n",
    "    )\n",
    "    \n",
    "    # Update analyze button based on the status\n",
    "    link_billing_output.then(\n",
    "        update_analyze_btn_based_on_status,\n",
    "        inputs=[status_output],\n",
    "        outputs=[analyze_btn]\n",
    "    )\n",
    "    \n",
    "    # Update tabs based on the status\n",
    "    link_billing_output.then(\n",
    "        update_tabs_based_on_status,\n",
    "        inputs=[status_output],\n",
    "        outputs=[tabs]\n",
    "    )\n",
    "\n",
    "    # Case Tab Interactions\n",
    "    def show_extraction_loading():\n",
    "        \"\"\"Show loading state when extraction starts.\"\"\"\n",
    "        return gr.update(visible=True), gr.update(interactive=False)\n",
    "    \n",
    "    def extract_and_display(case_text, disease_prompt, events_prompt):\n",
    "        \"\"\"Extract medical information and display results using custom prompts.\"\"\"\n",
    "        if not case_text.strip():\n",
    "            return (\n",
    "                gr.update(visible=False),  # extraction_box\n",
    "                \"\",  # disease_edit\n",
    "                \"\",  # events_edit\n",
    "                \"\",  # ai_extraction_display\n",
    "                {\"extracted\": False, \"disease\": \"\", \"events\": \"\", \"ai_disease\": \"\", \"ai_events\": \"\"},  # extraction_state\n",
    "                gr.update(interactive=False),  # proceed_button\n",
    "                \"‚ùå Please enter case notes first.\",  # case_status\n",
    "                gr.update(visible=False),  # extraction_loading\n",
    "                gr.update(interactive=True)  # extract_btn\n",
    "            )\n",
    "        \n",
    "        if not genai_client:\n",
    "            return (\n",
    "                gr.update(visible=True),\n",
    "                \"\",  # disease_edit\n",
    "                \"\",  # events_edit\n",
    "                \"‚ùå Please complete setup first.\",  # ai_extraction_display\n",
    "                {\"extracted\": False, \"disease\": \"\", \"events\": \"\", \"ai_disease\": \"\", \"ai_events\": \"\"},\n",
    "                gr.update(interactive=False),\n",
    "                \"\",\n",
    "                gr.update(visible=False),  # extraction_loading\n",
    "                gr.update(interactive=True)  # extract_btn\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            # Extract medical info with custom prompts\n",
    "            medical_info = extract_medical_info(case_text, genai_client, disease_prompt, events_prompt)\n",
    "            disease = medical_info.get('disease', '')\n",
    "            events = medical_info.get('events', '')\n",
    "            \n",
    "            # Format display for AI extraction reference\n",
    "            ai_display_text = f\"\"\"<div class=\"extraction-result\">\n",
    "<strong>AI Extracted Disease:</strong> {disease}\n",
    "\n",
    "<strong>AI Extracted Events:</strong>\n",
    "{events}\n",
    "</div>\"\"\"\n",
    "            \n",
    "            return (\n",
    "                gr.update(visible=True),  # extraction_box\n",
    "                disease,  # disease_edit - populate with AI extraction\n",
    "                events,  # events_edit - populate with AI extraction\n",
    "                ai_display_text,  # ai_extraction_display\n",
    "                {\"extracted\": True, \"disease\": disease, \"events\": events, \"ai_disease\": disease, \"ai_events\": events},  # extraction_state\n",
    "                gr.update(interactive=True),  # proceed_button\n",
    "                \"‚úÖ Information extracted successfully. You can edit the values before proceeding.\",  # case_status\n",
    "                gr.update(visible=False),  # extraction_loading\n",
    "                gr.update(interactive=True)  # extract_btn\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return (\n",
    "                gr.update(visible=True),\n",
    "                \"\",  # disease_edit\n",
    "                \"\",  # events_edit\n",
    "                f\"‚ùå Error extracting information: {str(e)}\",  # ai_extraction_display\n",
    "                {\"extracted\": False, \"disease\": \"\", \"events\": \"\", \"ai_disease\": \"\", \"ai_events\": \"\"},\n",
    "                gr.update(interactive=False),\n",
    "                \"\",\n",
    "                gr.update(visible=False),  # extraction_loading\n",
    "                gr.update(interactive=True)  # extract_btn\n",
    "            )\n",
    "    \n",
    "    # Extract button click handler\n",
    "    extract_btn.click(\n",
    "        show_extraction_loading,\n",
    "        outputs=[extraction_loading, extract_btn]\n",
    "    ).then(\n",
    "        extract_and_display,\n",
    "        inputs=[case_input, disease_prompt_input, events_prompt_input],\n",
    "        outputs=[extraction_box, disease_edit, events_edit, ai_extraction_display, extraction_state, proceed_to_persona_btn, case_status, extraction_loading, extract_btn]\n",
    "    )\n",
    "    \n",
    "    # Enable/disable extract button based on case input\n",
    "    def check_case_input(case_text):\n",
    "        if case_text.strip():\n",
    "            return gr.update(interactive=True)\n",
    "        else:\n",
    "            return gr.update(interactive=False)\n",
    "    \n",
    "    case_input.change(\n",
    "        check_case_input,\n",
    "        inputs=[case_input],\n",
    "        outputs=[extract_btn]\n",
    "    )\n",
    "    \n",
    "    # Load example button handler\n",
    "    def load_example_case():\n",
    "        \"\"\"Load example case notes and prompts.\"\"\"\n",
    "        return (\n",
    "            SAMPLE_CASE,\n",
    "            DISEASE_EXTRACTION_PROMPT,\n",
    "            EVENT_EXTRACTION_PROMPT\n",
    "        )\n",
    "\n",
    "    load_example_btn.click(\n",
    "        load_example_case,\n",
    "        outputs=[case_input, disease_prompt_input, events_prompt_input]\n",
    "    )\n",
    "    \n",
    "    # Event handlers for editable fields\n",
    "    def update_disease(new_disease, extraction_state):\n",
    "        \"\"\"Update the disease value in extraction state when user edits it.\"\"\"\n",
    "        if extraction_state:\n",
    "            extraction_state[\"disease\"] = new_disease\n",
    "        return extraction_state\n",
    "    \n",
    "    def update_events(new_events, extraction_state):\n",
    "        \"\"\"Update the events value in extraction state when user edits it.\"\"\"\n",
    "        if extraction_state:\n",
    "            extraction_state[\"events\"] = new_events\n",
    "        return extraction_state\n",
    "    \n",
    "    def reset_disease(extraction_state):\n",
    "        \"\"\"Reset disease to the original AI extraction.\"\"\"\n",
    "        if extraction_state and \"ai_disease\" in extraction_state:\n",
    "            return extraction_state[\"ai_disease\"], extraction_state\n",
    "        return \"\", extraction_state\n",
    "    \n",
    "    def reset_events(extraction_state):\n",
    "        \"\"\"Reset events to the original AI extraction.\"\"\"\n",
    "        if extraction_state and \"ai_events\" in extraction_state:\n",
    "            return extraction_state[\"ai_events\"], extraction_state\n",
    "        return \"\", extraction_state\n",
    "    \n",
    "    # Connect the handlers\n",
    "    disease_edit.change(\n",
    "        update_disease,\n",
    "        inputs=[disease_edit, extraction_state],\n",
    "        outputs=[extraction_state]\n",
    "    )\n",
    "    \n",
    "    events_edit.change(\n",
    "        update_events,\n",
    "        inputs=[events_edit, extraction_state],\n",
    "        outputs=[extraction_state]\n",
    "    )\n",
    "    \n",
    "    reset_disease_btn.click(\n",
    "        reset_disease,\n",
    "        inputs=[extraction_state],\n",
    "        outputs=[disease_edit, extraction_state]\n",
    "    )\n",
    "    \n",
    "    reset_events_btn.click(\n",
    "        reset_events,\n",
    "        inputs=[extraction_state],\n",
    "        outputs=[events_edit, extraction_state]\n",
    "    )\n",
    "\n",
    "    # Modified proceed button handler to go to Persona tab\n",
    "    def proceed_to_persona(case_text, extraction_state):\n",
    "        if not case_text.strip():\n",
    "            return \"‚ùå Please enter case notes first.\", gr.update(interactive=False), gr.update()\n",
    "        if not extraction_state.get(\"extracted\", False):\n",
    "            return \"‚ùå Please wait for information extraction to complete.\", gr.update(interactive=False), gr.update()\n",
    "        return \"‚úÖ Case notes and extracted information saved. Please customize your persona.\", gr.update(interactive=True), gr.update(selected=3)\n",
    "\n",
    "    proceed_to_persona_btn.click(\n",
    "        proceed_to_persona,\n",
    "        inputs=[case_input, extraction_state],\n",
    "        outputs=[case_status, analyze_btn, tabs]\n",
    "    )\n",
    "\n",
    "    # Persona Tab Interactions\n",
    "    def load_example_persona(personas):\n",
    "        \"\"\"Load a random example persona.\"\"\"\n",
    "        import random\n",
    "        persona_name = random.choice(list(personas.keys()))\n",
    "        return personas[persona_name]\n",
    "    \n",
    "    load_persona_btn.click(\n",
    "        load_example_persona,\n",
    "        inputs=[example_personas],\n",
    "        outputs=[persona_text]\n",
    "    )\n",
    "    \n",
    "    # Default criteria configuration\n",
    "    DEFAULT_CRITERIA = [\n",
    "        {\"name\": \"disease_match\", \"description\": \"Does the article match the patient's disease?\", \"weight\": 80, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"treatment_shown\", \"description\": \"Does the article show positive treatment results?\", \"weight\": 50, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"pediatric_focus\", \"description\": \"Does the article focus on pediatric patients?\", \"weight\": 60, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"clinical_trial\", \"description\": \"Is this a clinical trial?\", \"weight\": 70, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"novelty\", \"description\": \"Does the article present novel findings?\", \"weight\": 65, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"actionable_events_match\", \"description\": \"How many actionable events from the patient's case are mentioned in this article?\", \"weight\": 100, \"type\": \"numeric\", \"deletable\": True},\n",
    "        {\"name\": \"human_clinical_data\", \"description\": \"Does the article include human clinical data?\", \"weight\": 30, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"cell_studies\", \"description\": \"Does the article include cell studies?\", \"weight\": 5, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"mice_studies\", \"description\": \"Does the article include mice studies?\", \"weight\": 10, \"type\": \"boolean\", \"deletable\": True},\n",
    "        {\"name\": \"journal_impact\", \"description\": \"Journal impact factor (SJR)\", \"weight\": 10, \"type\": \"special_journal\", \"deletable\": True},\n",
    "        {\"name\": \"year\", \"description\": \"Publication year penalty\", \"weight\": 30, \"type\": \"special_year\", \"deletable\": True}\n",
    "    ]\n",
    "    \n",
    "    def calculate_total_weight(criteria_list):\n",
    "        \"\"\"Calculate total weight from criteria list.\"\"\"\n",
    "        total = sum(c['weight'] for c in criteria_list if c is not None)\n",
    "        return f\"**Total Weight:** {total}\"\n",
    "    \n",
    "    def update_criteria_display(criteria_list):\n",
    "        \"\"\"Update all criterion slot displays based on the criteria list.\"\"\"\n",
    "        updates = []\n",
    "        \n",
    "        # Type badge styling\n",
    "        type_colors = {\n",
    "            'boolean': 'üü¢',\n",
    "            'numeric': 'üîµ', \n",
    "            'direct': 'üü†',\n",
    "            'special_journal': 'üü£',\n",
    "            'special_year': 'üî¥'\n",
    "        }\n",
    "        \n",
    "        for i in range(20):\n",
    "            if i < len(criteria_list) and criteria_list[i] is not None:\n",
    "                criterion = criteria_list[i]\n",
    "                # Row visibility\n",
    "                updates.append(gr.update(visible=True))\n",
    "                # Description\n",
    "                updates.append(gr.update(value=f\"**{criterion['description']}**\"))\n",
    "                # Type info\n",
    "                type_emoji = type_colors.get(criterion['type'], '‚ö´')\n",
    "                updates.append(gr.update(value=f\"{type_emoji} Type: `{criterion['type']}` | Name: `{criterion['name']}`\"))\n",
    "                # Slider value\n",
    "                updates.append(gr.update(value=criterion['weight']))\n",
    "                # Delete button\n",
    "                if criterion.get('deletable', True):\n",
    "                    updates.append(gr.update(visible=True, interactive=True))\n",
    "                else:\n",
    "                    updates.append(gr.update(visible=False))\n",
    "            else:\n",
    "                # Hide this slot\n",
    "                updates.append(gr.update(visible=False))\n",
    "                updates.append(gr.update(value=\"\"))\n",
    "                updates.append(gr.update(value=\"\"))\n",
    "                updates.append(gr.update(value=0))\n",
    "                updates.append(gr.update(visible=False))\n",
    "        \n",
    "        # Add total weight\n",
    "        updates.append(calculate_total_weight(criteria_list))\n",
    "        \n",
    "        return updates\n",
    "    \n",
    "    def show_add_criterion_dialog(criteria_list):\n",
    "        \"\"\"Show the dialog for adding a new criterion if there's space.\"\"\"\n",
    "        if len([c for c in criteria_list if c is not None]) >= 20:\n",
    "            return gr.update(visible=False), gr.update(visible=True, value=\"‚ö†Ô∏è Maximum 20 criteria reached\")\n",
    "        return gr.update(visible=True), gr.update(visible=False)\n",
    "    \n",
    "    def hide_add_criterion_dialog():\n",
    "        \"\"\"Hide the add criterion dialog.\"\"\"\n",
    "        return gr.update(visible=False), \"\", \"boolean\", 10\n",
    "    \n",
    "    def add_new_criterion_with_details(criteria_list, description, criterion_type, weight):\n",
    "        \"\"\"Add a new custom criterion with user-provided details.\"\"\"\n",
    "        if not description.strip():\n",
    "            return [criteria_list] + update_criteria_display(criteria_list) + [gr.update(visible=True)]\n",
    "        \n",
    "        # Check if we have space\n",
    "        if len([c for c in criteria_list if c is not None]) >= 20:\n",
    "            return [criteria_list] + update_criteria_display(criteria_list) + [gr.update(visible=True)]\n",
    "        \n",
    "        # Generate a safe name from description\n",
    "        import re\n",
    "        safe_name = re.sub(r'[^a-zA-Z0-9_]', '_', description.lower())[:30]\n",
    "        if not safe_name or safe_name[0].isdigit():\n",
    "            safe_name = f\"custom_{len([c for c in criteria_list if c is not None])}\"\n",
    "        \n",
    "        new_criterion = {\n",
    "            \"name\": safe_name,\n",
    "            \"description\": description.strip(),\n",
    "            \"weight\": weight,\n",
    "            \"type\": criterion_type,\n",
    "            \"deletable\": True,\n",
    "            \"user_defined\": True\n",
    "        }\n",
    "        \n",
    "        # Add to the list\n",
    "        new_list = criteria_list.copy()\n",
    "        new_list.append(new_criterion)\n",
    "        \n",
    "        return [new_list] + update_criteria_display(new_list) + [gr.update(visible=False)]\n",
    "    \n",
    "    def update_criterion_weight(criteria_list, slot_index, new_weight):\n",
    "        \"\"\"Update the weight for a specific criterion.\"\"\"\n",
    "        if slot_index < len(criteria_list) and criteria_list[slot_index] is not None:\n",
    "            new_list = criteria_list.copy()\n",
    "            new_list[slot_index]['weight'] = new_weight\n",
    "            return new_list, calculate_total_weight(new_list)\n",
    "        return criteria_list, calculate_total_weight(criteria_list)\n",
    "    \n",
    "    def delete_criterion(criteria_list, slot_index):\n",
    "        \"\"\"Delete a criterion from a specific slot.\"\"\"\n",
    "        if slot_index < len(criteria_list) and criteria_list[slot_index] is not None:\n",
    "            if criteria_list[slot_index].get('deletable', True):\n",
    "                new_list = criteria_list.copy()\n",
    "                new_list.pop(slot_index)\n",
    "                return [new_list] + update_criteria_display(new_list)\n",
    "        return [criteria_list] + update_criteria_display(criteria_list)\n",
    "    \n",
    "    def reset_to_defaults():\n",
    "        \"\"\"Reset criteria to defaults.\"\"\"\n",
    "        return [DEFAULT_CRITERIA.copy()] + update_criteria_display(DEFAULT_CRITERIA.copy())\n",
    "    \n",
    "    # Initialize criteria state on load\n",
    "    def initialize_criteria():\n",
    "        criteria = DEFAULT_CRITERIA.copy()\n",
    "        return [criteria] + update_criteria_display(criteria)\n",
    "    \n",
    "    # Set up initial criteria\n",
    "    all_outputs = [criteria_state]\n",
    "    for i in range(20):\n",
    "        all_outputs.extend([\n",
    "            criterion_rows[i],\n",
    "            criterion_descriptions[i],\n",
    "            criterion_type_infos[i],\n",
    "            criterion_sliders[i],\n",
    "            criterion_delete_btns[i]\n",
    "        ])\n",
    "    all_outputs.append(total_weight_display)\n",
    "    \n",
    "    demo.load(\n",
    "        initialize_criteria,\n",
    "        outputs=all_outputs\n",
    "    )\n",
    "    \n",
    "    # Criteria management event handlers\n",
    "    add_criterion_btn.click(\n",
    "        show_add_criterion_dialog,\n",
    "        inputs=[criteria_state],\n",
    "        outputs=[add_criterion_dialog, total_weight_display]\n",
    "    )\n",
    "    \n",
    "    cancel_add_btn.click(\n",
    "        hide_add_criterion_dialog,\n",
    "        outputs=[add_criterion_dialog, new_criterion_description, new_criterion_type, new_criterion_weight]\n",
    "    )\n",
    "    \n",
    "    confirm_add_btn.click(\n",
    "        add_new_criterion_with_details,\n",
    "        inputs=[criteria_state, new_criterion_description, new_criterion_type, new_criterion_weight],\n",
    "        outputs=[criteria_state] + all_outputs[1:] + [add_criterion_dialog]\n",
    "    ).then(\n",
    "        lambda: (\"\", \"boolean\", 10),\n",
    "        outputs=[new_criterion_description, new_criterion_type, new_criterion_weight]\n",
    "    )\n",
    "    \n",
    "    reset_criteria_btn.click(\n",
    "        reset_to_defaults,\n",
    "        outputs=all_outputs\n",
    "    )\n",
    "    \n",
    "    # Set up weight slider handlers for each slot\n",
    "    for i in range(20):\n",
    "        criterion_sliders[i].change(\n",
    "            lambda weight, state, idx=i: update_criterion_weight(state, idx, weight),\n",
    "            inputs=[criterion_sliders[i], criteria_state],\n",
    "            outputs=[criteria_state, total_weight_display]\n",
    "        )\n",
    "    \n",
    "    # Set up delete button handlers for each slot\n",
    "    for i in range(20):\n",
    "        criterion_delete_btns[i].click(\n",
    "            lambda state, idx=i: delete_criterion(state, idx),\n",
    "            inputs=[criteria_state],\n",
    "            outputs=all_outputs\n",
    "        )\n",
    "    \n",
    "    # Generator function for two-phase progressive analysis\n",
    "    def run_two_phase_analysis(case_text, analysis_config, persona, criteria, extraction_state):\n",
    "        \"\"\"Generator that yields analysis progress updates with two-phase approach.\"\"\"\n",
    "        if not genai_client or not bq_client:\n",
    "            yield {\"status\": \"error\", \"message\": \"‚ùå Please complete setup first.\"}\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get configuration\n",
    "            default_articles = int(analysis_config.get(\"default_articles\", 5))\n",
    "            min_per_event = int(analysis_config.get(\"min_per_event\", 3))\n",
    "            max_articles = int(analysis_config.get(\"max_articles\", 50))\n",
    "            \n",
    "            # Extract disease and events with IDs\n",
    "            disease = extraction_state.get('disease', '')\n",
    "            events_list = extraction_state.get('events_list', [])\n",
    "            events_with_ids = extraction_state.get('events_with_ids', {})\n",
    "            \n",
    "            if not events_with_ids:\n",
    "                # Fallback: generate IDs if not present\n",
    "                events_text = extraction_state.get('events', '')\n",
    "                if '\"' in events_text:\n",
    "                    import re\n",
    "                    events_list = re.findall(r'\"([^\"]+)\"', events_text)\n",
    "                else:\n",
    "                    events_list = [e.strip() for e in events_text.split('\\n') if e.strip()]\n",
    "                \n",
    "                events_with_ids = {f\"event_{i}\": event for i, event in enumerate(events_list, 1)}\n",
    "                extraction_state['events_list'] = events_list\n",
    "                extraction_state['events_with_ids'] = events_with_ids\n",
    "            \n",
    "            yield {\"status\": \"starting\", \"message\": \"Starting two-phase analysis...\"}\n",
    "            \n",
    "            # Phase 1: Event Coverage Check\n",
    "            yield {\"status\": \"phase1_start\", \"message\": \"Phase 1: Checking event coverage...\"}\n",
    "            \n",
    "            event_coverage = {event_id: [] for event_id in events_with_ids.keys()}\n",
    "            total_articles_searched = 0\n",
    "            selected_pmids = set()\n",
    "            all_searched_articles = []  # Keep all articles for potential full analysis\n",
    "            \n",
    "            embedding_model_path = f\"{PROJECT_ID}.{USER_DATASET}.textembed\"\n",
    "            \n",
    "            while total_articles_searched < max_articles:\n",
    "                # Check if all events have minimum coverage\n",
    "                all_covered = all(len(pmids) >= min_per_event for pmids in event_coverage.values())\n",
    "                if all_covered:\n",
    "                    break\n",
    "                \n",
    "                # Search next batch\n",
    "                batch_start = total_articles_searched + 1\n",
    "                batch_end = min(total_articles_searched + default_articles, max_articles)\n",
    "                \n",
    "                yield {\n",
    "                    \"status\": \"phase1_searching\",\n",
    "                    \"message\": f\"Searching articles {batch_start}-{batch_end}...\",\n",
    "                    \"coverage\": event_coverage\n",
    "                }\n",
    "                \n",
    "                # Fetch articles with offset\n",
    "                articles_df = search_pubmed_articles(\n",
    "                    disease, events_list, bq_client, embedding_model_path, \n",
    "                    PUBMED_TABLE, default_articles, offset=total_articles_searched\n",
    "                )\n",
    "                \n",
    "                if articles_df.empty:\n",
    "                    break\n",
    "                \n",
    "                all_searched_articles.append(articles_df)\n",
    "                \n",
    "                # Analyze batch for event coverage\n",
    "                yield {\n",
    "                    \"status\": \"phase1_analyzing\",\n",
    "                    \"message\": f\"Analyzing batch for event coverage...\",\n",
    "                    \"coverage\": event_coverage\n",
    "                }\n",
    "                \n",
    "                coverage_results = analyze_event_coverage_batch(\n",
    "                    articles_df, disease, events_with_ids, bq_client\n",
    "                )\n",
    "                \n",
    "                # Update coverage tracking using PMCID\n",
    "                for result in coverage_results:\n",
    "                    pmcid = result['PMCID']\n",
    "                    event_ids_str = result.get('event_ids', '')\n",
    "                    \n",
    "                    if event_ids_str:\n",
    "                        event_ids = [e.strip() for e in event_ids_str.split(',') if e.strip()]\n",
    "                        for event_id in event_ids:\n",
    "                            if event_id in event_coverage:\n",
    "                                if pmcid not in event_coverage[event_id]:\n",
    "                                    event_coverage[event_id].append(pmcid)\n",
    "                                selected_pmids.add(pmcid)\n",
    "                \n",
    "                total_articles_searched += len(articles_df)\n",
    "                \n",
    "                # Report coverage status\n",
    "                coverage_status = []\n",
    "                for event_id, event_text in events_with_ids.items():\n",
    "                    count = len(event_coverage[event_id])\n",
    "                    status_text = f\"{event_text[:30]}...: {count}/{min_per_event}\"\n",
    "                    if count >= min_per_event:\n",
    "                        status_text = f\"‚úì {status_text}\"\n",
    "                    coverage_status.append(status_text)\n",
    "                \n",
    "                yield {\n",
    "                    \"status\": \"phase1_progress\",\n",
    "                    \"message\": f\"Searched {total_articles_searched} articles\",\n",
    "                    \"coverage\": event_coverage,\n",
    "                    \"coverage_status\": coverage_status\n",
    "                }\n",
    "            \n",
    "            # Phase 1 Complete\n",
    "            all_covered = all(len(pmids) >= min_per_event for pmids in event_coverage.values())\n",
    "            phase1_summary = f\"Phase 1 complete: Searched {total_articles_searched} articles, found {len(selected_pmids)} relevant articles\"\n",
    "            \n",
    "            if not all_covered:\n",
    "                phase1_summary += \" (Warning: Some events did not meet minimum coverage)\"\n",
    "            \n",
    "            yield {\n",
    "                \"status\": \"phase1_complete\",\n",
    "                \"message\": phase1_summary,\n",
    "                \"selected_articles\": len(selected_pmids),\n",
    "                \"coverage\": event_coverage\n",
    "            }\n",
    "            \n",
    "            # Phase 2: Full Analysis - Analyze ALL articles\n",
    "            # Combine all searched articles\n",
    "            all_articles_df = pd.concat(all_searched_articles, ignore_index=True) if all_searched_articles else pd.DataFrame()\n",
    "            \n",
    "            if all_articles_df.empty:\n",
    "                yield {\n",
    "                    \"status\": \"complete\",\n",
    "                    \"message\": \"No articles found\",\n",
    "                    \"results\": {\n",
    "                        'articles': [],\n",
    "                        'disease': disease,\n",
    "                        'events': events_list,\n",
    "                        'case_text': case_text,\n",
    "                        'persona': persona,\n",
    "                        'criteria': criteria\n",
    "                    }\n",
    "                }\n",
    "                return\n",
    "            \n",
    "            yield {\"status\": \"phase2_start\", \"message\": f\"Phase 2: Performing full analysis on ALL {len(all_articles_df)} articles found...\"}\n",
    "            \n",
    "            # Use all articles, not just selected ones\n",
    "            selected_articles_df = all_articles_df\n",
    "            \n",
    "            # Analyze selected articles one by one for UI updates\n",
    "            analyzed_articles = []\n",
    "            \n",
    "            for idx, (_, article_row) in enumerate(selected_articles_df.iterrows()):\n",
    "                yield {\n",
    "                    \"status\": \"phase2_analyzing\",\n",
    "                    \"current\": idx + 1,\n",
    "                    \"total\": len(selected_articles_df),\n",
    "                    \"message\": f\"Full analysis: article {idx + 1} of {len(selected_articles_df)}...\"\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    # Create single-row DataFrame\n",
    "                    single_article_df = pd.DataFrame([article_row])\n",
    "                    \n",
    "                    # Full analysis with all criteria\n",
    "                    analysis_results = analyze_article_batch_with_criteria(\n",
    "                        single_article_df, disease, events_list, bq_client, \n",
    "                        journal_impact_dict, persona, criteria\n",
    "                    )\n",
    "                    \n",
    "                    if analysis_results and len(analysis_results) > 0:\n",
    "                        analysis = analysis_results[0]\n",
    "                        \n",
    "                        # Merge analysis results with article data\n",
    "                        article_data = article_row.to_dict()\n",
    "                        article_data.update(analysis)\n",
    "                        \n",
    "                        # Calculate score and get breakdown\n",
    "                        score, point_breakdown = calculate_dynamic_score(analysis, criteria, journal_impact_dict)\n",
    "                        \n",
    "                        article_data['score'] = score\n",
    "                        article_data['point_breakdown'] = point_breakdown\n",
    "                        article_data['content'] = article_row.get('content', '')\n",
    "                        article_data['pmcid'] = article_row.get('PMCID', '')\n",
    "                        article_data['pmid'] = article_row.get('PMID', '')  # May be None\n",
    "                        \n",
    "                        analyzed_articles.append(article_data)\n",
    "                        \n",
    "                        # Yield the analyzed article\n",
    "                        yield {\n",
    "                            \"status\": \"article_complete\",\n",
    "                            \"current\": idx + 1,\n",
    "                            \"total\": len(selected_articles_df),\n",
    "                            \"article\": {\n",
    "                                \"score\": score,\n",
    "                                \"point_breakdown\": point_breakdown,\n",
    "                                \"title\": analysis.get('title', 'Unknown Title'),\n",
    "                                \"journal\": analysis.get('journal_title', 'Unknown Journal'),\n",
    "                                \"year\": analysis.get('year', 'N/A'),\n",
    "                                \"pmid\": article_row.get('PMID', ''),\n",
    "                                \"pmcid\": article_row.get('PMCID', ''),\n",
    "                                \"content\": article_row.get('content', ''),\n",
    "                                \"metadata\": analysis\n",
    "                            }\n",
    "                        }\n",
    "                    else:\n",
    "                        yield {\n",
    "                            \"status\": \"article_failed\",\n",
    "                            \"current\": idx + 1,\n",
    "                            \"total\": len(selected_articles_df),\n",
    "                            \"message\": f\"Failed to analyze article {idx + 1}\"\n",
    "                        }\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing article {idx + 1}: {str(e)}\")\n",
    "                    yield {\n",
    "                        \"status\": \"article_failed\",\n",
    "                        \"current\": idx + 1,\n",
    "                        \"total\": len(selected_articles_df),\n",
    "                        \"message\": f\"Error analyzing article {idx + 1}: {str(e)}\"\n",
    "                    }\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting\n",
    "                if idx < len(selected_articles_df) - 1:\n",
    "                    time.sleep(1)\n",
    "            \n",
    "            # Final results\n",
    "            yield {\n",
    "                \"status\": \"complete\",\n",
    "                \"message\": f\"‚úÖ Analysis complete! Analyzed {len(analyzed_articles)} articles.\",\n",
    "                \"results\": {\n",
    "                    'articles': analyzed_articles,\n",
    "                    'disease': disease,\n",
    "                    'events': events_list,\n",
    "                    'case_text': case_text,\n",
    "                    'persona': persona,\n",
    "                    'criteria': criteria,\n",
    "                    'total_searched': total_articles_searched,\n",
    "                    'event_coverage': event_coverage\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            yield {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"‚ùå Error during analysis: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    # Helper function to generate article HTML card\n",
    "    def generate_article_html(article, idx):\n",
    "        \"\"\"Generate consistent HTML for an article card.\"\"\"\n",
    "        # Format points breakdown with better visibility\n",
    "        breakdown_items = []\n",
    "        \n",
    "        if article.get('point_breakdown'):\n",
    "            for key, value in article.get('point_breakdown', {}).items():\n",
    "                formatted_key = key.replace('_', ' ').title()\n",
    "                if value > 0:\n",
    "                    breakdown_items.append(f'<span style=\"color: #28a745; font-weight: bold;\">{formatted_key}: +{value:.1f}</span>')\n",
    "                elif value < 0:\n",
    "                    breakdown_items.append(f'<span style=\"color: #dc3545; font-weight: bold;\">{formatted_key}: {value:.1f}</span>')\n",
    "        \n",
    "        # Get metadata\n",
    "        metadata = article.get('metadata', article)\n",
    "        \n",
    "        # Create events display - handle string format\n",
    "        events_html = \"\"\n",
    "        actionable_events = metadata.get('actionable_events', '')\n",
    "        if actionable_events:\n",
    "            if isinstance(actionable_events, str):\n",
    "                # Parse JSON string or split by comma\n",
    "                try:\n",
    "                    import json as json_module\n",
    "                    events_list = json_module.loads(actionable_events)\n",
    "                except:\n",
    "                    # Treat as comma-separated\n",
    "                    events_list = [e.strip() for e in actionable_events.split(',') if e.strip()]\n",
    "            else:\n",
    "                events_list = actionable_events\n",
    "            \n",
    "            # Process events\n",
    "            if isinstance(events_list, list):\n",
    "                for event in events_list:\n",
    "                    if isinstance(event, dict):\n",
    "                        event_text = event.get('event', '')\n",
    "                        matches = event.get('matches_query', False)\n",
    "                        color = '#28a745' if matches else '#6c757d'\n",
    "                        weight = 'bold' if matches else 'normal'\n",
    "                        events_html += f'<span style=\"color: {color}; font-weight: {weight}; margin-right: 10px;\">{event_text}</span>'\n",
    "                    else:\n",
    "                        # Simple string\n",
    "                        events_html += f'<span style=\"color: #6c757d; margin-right: 10px;\">{event}</span>'\n",
    "        \n",
    "        # Paper type and other metadata\n",
    "        paper_type = metadata.get('paper_type', 'Unknown')\n",
    "        \n",
    "        return f\"\"\"\n",
    "        <div class='article-card'>\n",
    "            <div style='display: flex; justify-content: space-between; align-items: start;'>\n",
    "                <h4 style='margin-top: 0; flex: 1; color: #212529;'>{idx + 1}. {article.get('title', 'Unknown')}</h4>\n",
    "                <div style='text-align: right;'>\n",
    "                    <span style='font-size: 32px; font-weight: bold; color: #007bff; display: block;'>{article.get('score', 0):.1f}</span>\n",
    "                    <span style='font-size: 14px; color: #6c757d;'>Total Score</span>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class='score-breakdown-box'>\n",
    "                <h5 style='margin-top: 0; color: #495057;'>üìä Score Breakdown</h5>\n",
    "                <div style='margin: 10px 0;'>\n",
    "                    {' | '.join(breakdown_items) if breakdown_items else '<span style=\"color: #6c757d;\">No scoring criteria matched</span>'}\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div style='margin: 10px 0; color: #212529;'>\n",
    "                <strong style='color: #212529;'>Journal:</strong> {article.get('journal_title', metadata.get('journal_title', 'Unknown'))} | \n",
    "                <strong style='color: #212529;'>Year:</strong> {article.get('year', metadata.get('year', 'N/A'))} | \n",
    "                <strong style='color: #212529;'>Type:</strong> {paper_type}\n",
    "            </div>\n",
    "            \n",
    "            <div style='margin: 10px 0;'>\n",
    "                <strong style='color: #212529;'>Links:</strong> \n",
    "                <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/{article.get('pmcid', '')}/\" target=\"_blank\" style=\"color: #0066cc; text-decoration: underline; margin-right: 15px;\">\n",
    "                    üîó PMC Full Text (PMCID: {article.get('pmcid', 'N/A')})\n",
    "                </a>\n",
    "                {f'<a href=\"https://pubmed.ncbi.nlm.nih.gov/{article.get(\"pmid\")}/\" target=\"_blank\" style=\"color: #0066cc; text-decoration: underline;\">üìÑ PubMed (PMID: {article.get(\"pmid\")})</a>' if article.get('pmid') else ''}\n",
    "            </div>\n",
    "            \n",
    "            <div style='margin: 10px 0;'>\n",
    "                <strong style='color: #212529;'>Actionable Events Found:</strong><br/>\n",
    "                <div style='margin-top: 5px;'>\n",
    "                    {events_html if events_html else '<span style=\"color: #6c757d;\">None found</span>'}\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <details style='margin-top: 15px;'>\n",
    "                <summary style=\"cursor: pointer; color: #0066cc; font-weight: bold;\">üìë View Full Article</summary>\n",
    "                <div class='article-content-box'>\n",
    "                    <pre>{article.get('content', 'No content available')}</pre>\n",
    "                </div>\n",
    "            </details>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Function to update the UI based on generator output\n",
    "    def update_analysis_display(progress_data, current_results, is_active):\n",
    "        \"\"\"Update the display based on progress data.\"\"\"\n",
    "        if not progress_data:\n",
    "            return [current_results, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), is_active]\n",
    "        \n",
    "        status = progress_data.get(\"status\", \"\")\n",
    "        \n",
    "        if status == \"error\":\n",
    "            return [\n",
    "                current_results,\n",
    "                gr.update(value=progress_data.get(\"message\", \"Error\")),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(visible=True, value=progress_data.get(\"message\", \"\")),\n",
    "                gr.update(visible=False),\n",
    "                False\n",
    "            ]\n",
    "        \n",
    "        elif status == \"starting\":\n",
    "            return [\n",
    "                [],  # Clear results\n",
    "                gr.update(value=\"üîÑ Starting analysis...\"),\n",
    "                gr.update(value=pd.DataFrame()),\n",
    "                gr.update(value=\"\"),\n",
    "                gr.update(visible=False),\n",
    "                gr.update(visible=True),\n",
    "                True\n",
    "            ]\n",
    "        \n",
    "        elif status == \"searching\":\n",
    "            return [\n",
    "                current_results,\n",
    "                gr.update(value=f\"üîç {progress_data.get('message', '')}\"),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                is_active\n",
    "            ]\n",
    "        \n",
    "        elif status == \"search_complete\":\n",
    "            return [\n",
    "                current_results,\n",
    "                gr.update(value=f\"üìö {progress_data.get('message', '')}\"),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                is_active\n",
    "            ]\n",
    "        \n",
    "        elif status == \"analyzing\":\n",
    "            current = progress_data.get(\"current\", 0)\n",
    "            total = progress_data.get(\"total\", 0)\n",
    "            progress_pct = (current / total * 100) if total > 0 else 0\n",
    "            return [\n",
    "                current_results,\n",
    "                gr.update(value=f\"üî¨ Analyzing article {current}/{total} ({progress_pct:.0f}%)\"),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                is_active\n",
    "            ]\n",
    "        \n",
    "        elif status == \"article_complete\":\n",
    "            # Add the new article to results\n",
    "            new_results = current_results.copy() if current_results else []\n",
    "            article = progress_data.get(\"article\", {})\n",
    "            new_results.append(article)\n",
    "            \n",
    "            # Sort by score descending\n",
    "            new_results.sort(key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "            \n",
    "            # Create DataFrame for display\n",
    "            df_data = []\n",
    "            for r in new_results:\n",
    "                df_data.append({\n",
    "                    \"Score\": f\"{r.get('score', 0):.1f}\",\n",
    "                    \"Title\": r.get('title', 'Unknown')[:80] + \"...\" if len(r.get('title', '')) > 80 else r.get('title', 'Unknown'),\n",
    "                    \"Journal\": r.get('journal', 'Unknown'),\n",
    "                    \"Year\": r.get('year', 'N/A'),\n",
    "                    \"Status\": \"‚úÖ Analyzed\"\n",
    "                })\n",
    "            \n",
    "            display_df = pd.DataFrame(df_data)\n",
    "            \n",
    "            # Update detailed analysis HTML using consistent generator\n",
    "            detailed_html = \"<div style='max-height: 800px; overflow-y: auto;'>\"\n",
    "            for idx, r in enumerate(new_results[:10]):  # Show top 10 in detail\n",
    "                detailed_html += generate_article_html(r, idx)\n",
    "            detailed_html += \"</div>\"\n",
    "            \n",
    "            current = progress_data.get(\"current\", 0)\n",
    "            total = progress_data.get(\"total\", 0)\n",
    "            \n",
    "            return [\n",
    "                new_results,\n",
    "                gr.update(value=f\"üî¨ Analyzed {current}/{total} articles\"),\n",
    "                gr.update(value=display_df),\n",
    "                gr.update(value=detailed_html),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                is_active\n",
    "            ]\n",
    "        \n",
    "        elif status == \"article_failed\":\n",
    "            current = progress_data.get(\"current\", 0)\n",
    "            total = progress_data.get(\"total\", 0)\n",
    "            return [\n",
    "                current_results,\n",
    "                gr.update(value=f\"‚ö†Ô∏è Article {current}/{total} failed - {progress_data.get('message', '')}\"),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                is_active\n",
    "            ]\n",
    "        \n",
    "        elif status == \"complete\":\n",
    "            # Final update with all results\n",
    "            results = progress_data.get(\"results\", {})\n",
    "            articles = results.get(\"articles\", [])\n",
    "            \n",
    "            # Sort articles by score\n",
    "            articles.sort(key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "            \n",
    "            # Create final DataFrame with interactive elements\n",
    "            df_data = []\n",
    "            for r in articles:\n",
    "                df_data.append({\n",
    "                    \"Score\": f\"{r.get('score', 0):.1f}\",\n",
    "                    \"PMID\": r.get(\"pmid\", \"N/A\"),\n",
    "                    \"Title\": r.get('title', 'Unknown')[:80] + \"...\" if len(r.get('title', '')) > 80 else r.get('title', 'Unknown'),\n",
    "                    \"Journal\": r.get('journal_title', 'Unknown'),\n",
    "                    \"Year\": r.get('year', 'N/A'),\n",
    "                    \"Status\": \"‚úÖ Complete\"\n",
    "                })\n",
    "            \n",
    "            display_df = pd.DataFrame(df_data)\n",
    "            \n",
    "            # Create enhanced detailed HTML using consistent generator\n",
    "            detailed_html = \"<div style='max-height: 800px; overflow-y: auto;'>\"\n",
    "            detailed_html += \"<h3>Detailed Results</h3>\"\n",
    "            \n",
    "            for idx, article in enumerate(articles):\n",
    "                detailed_html += generate_article_html(article, idx)\n",
    "            \n",
    "            detailed_html += \"</div>\"\n",
    "            \n",
    "            # Summary message\n",
    "            summary = f\"\"\"\n",
    "            ### Analysis Summary\n",
    "            \n",
    "            - **Disease:** {results.get('disease', 'Unknown')}\n",
    "            - **Events:** {', '.join(results.get('events', []))}\n",
    "            - **Articles Analyzed:** {len(articles)}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Only add top score if articles exist\n",
    "            if articles and len(articles) > 0:\n",
    "                summary += f\"\\n- **Top Score:** {articles[0].get('score', 0):.1f}\"\n",
    "            else:\n",
    "                summary += f\"\\n- **Top Score:** N/A\"\n",
    "            \n",
    "            if articles:\n",
    "                summary += \"\\n\\n#### Top 5 Articles:\\n\"\n",
    "                for i, article in enumerate(articles[:5]):\n",
    "                    summary += f\"\\n{i+1}. **{article.get('title', 'Unknown')}** (Score: {article.get('score', 0):.1f})\"\n",
    "                    if article.get('pmid'):\n",
    "                        summary += f\" - [PubMed](https://pubmed.ncbi.nlm.nih.gov/{article.get('pmid')}/)\"\n",
    "            else:\n",
    "                summary += \"\\n\\n‚ö†Ô∏è No articles were successfully analyzed. This may be due to API quota limits or processing errors.\"\n",
    "            \n",
    "            # Debug log\n",
    "            print(f\"DEBUG: Analysis complete with {len(articles)} articles\")\n",
    "            \n",
    "            return [\n",
    "                articles,\n",
    "                gr.update(value=progress_data.get(\"message\", \"\")),\n",
    "                gr.update(value=display_df),\n",
    "                gr.update(value=detailed_html),\n",
    "                gr.update(visible=True),  # Show final_analysis_btn\n",
    "                gr.update(visible=False),\n",
    "                False\n",
    "            ]\n",
    "        \n",
    "        return [current_results, gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), is_active]\n",
    "    \n",
    "    # New functions to handle configuration updates\n",
    "    def update_analysis_config(default_articles, min_per_event):\n",
    "        \"\"\"Update the analysis configuration state.\"\"\"\n",
    "        return {\n",
    "            \"default_articles\": int(default_articles),\n",
    "            \"min_per_event\": int(min_per_event),\n",
    "            \"max_articles\": 50\n",
    "        }\n",
    "    \n",
    "    # Connect configuration inputs to state\n",
    "    default_articles_input.change(\n",
    "        update_analysis_config,\n",
    "        inputs=[default_articles_input, min_articles_per_event],\n",
    "        outputs=[analysis_config]\n",
    "    )\n",
    "    \n",
    "    min_articles_per_event.change(\n",
    "        update_analysis_config,\n",
    "        inputs=[default_articles_input, min_articles_per_event],\n",
    "        outputs=[analysis_config]\n",
    "    )\n",
    "    \n",
    "    # Function to run the two-phase analysis with proper generator handling\n",
    "    def run_full_analysis_two_phase(case_text, analysis_config, persona, criteria, extraction_state):\n",
    "        \"\"\"Run the two-phase analysis with progressive updates.\"\"\"\n",
    "        # Initialize states\n",
    "        results = []\n",
    "        is_active = True\n",
    "        \n",
    "        # Create the generator for two-phase analysis\n",
    "        generator = run_two_phase_analysis(case_text, analysis_config, persona, criteria, extraction_state)\n",
    "        \n",
    "        # Process each yield from the generator\n",
    "        for progress_data in generator:\n",
    "            if not is_active:  # Check if analysis was stopped\n",
    "                break\n",
    "                \n",
    "            # Update the display based on status\n",
    "            status = progress_data.get(\"status\", \"\")\n",
    "            \n",
    "            # Handle phase 1 specific statuses\n",
    "            if status in [\"phase1_start\", \"phase1_searching\", \"phase1_analyzing\", \"phase1_progress\", \"phase1_complete\"]:\n",
    "                if status == \"phase1_progress\":\n",
    "                    # Format coverage status for display\n",
    "                    coverage_status = progress_data.get(\"coverage_status\", [])\n",
    "                    coverage_html = \"<br>\".join(coverage_status)\n",
    "                    yield [\n",
    "                        results,\n",
    "                        gr.update(value=f\"{progress_data.get('message', '')}\"),\n",
    "                        gr.update(visible=True, value=coverage_html),\n",
    "                        gr.update(),\n",
    "                        gr.update(),\n",
    "                        gr.update(),\n",
    "                        gr.update(visible=True),\n",
    "                        is_active\n",
    "                    ]\n",
    "                else:\n",
    "                    yield [\n",
    "                        results,\n",
    "                        gr.update(value=progress_data.get(\"message\", \"\")),\n",
    "                        gr.update(visible=True),\n",
    "                        gr.update(),\n",
    "                        gr.update(),\n",
    "                        gr.update(),\n",
    "                        gr.update(visible=True),\n",
    "                        is_active\n",
    "                    ]\n",
    "            elif status == \"phase2_start\":\n",
    "                yield [\n",
    "                    results,\n",
    "                    gr.update(value=progress_data.get(\"message\", \"\")),\n",
    "                    gr.update(visible=False),  # Hide coverage display for phase 2\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    gr.update(visible=True),\n",
    "                    is_active\n",
    "                ]\n",
    "            elif status == \"phase2_analyzing\":\n",
    "                current = progress_data.get(\"current\", 0)\n",
    "                total = progress_data.get(\"total\", 0)\n",
    "                progress_pct = (current / total * 100) if total > 0 else 0\n",
    "                yield [\n",
    "                    results,\n",
    "                    gr.update(value=f\"Phase 2: Analyzing article {current}/{total} ({progress_pct:.0f}%)\"),\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    gr.update(),\n",
    "                    is_active\n",
    "                ]\n",
    "            else:\n",
    "                # Use the regular update display for other statuses\n",
    "                results, progress_update, df_update, html_update, summary_update, stop_btn_update, is_active = update_analysis_display(\n",
    "                    progress_data, results, is_active\n",
    "                )\n",
    "                \n",
    "                # Add event coverage display update\n",
    "                yield [\n",
    "                    results,\n",
    "                    progress_update,\n",
    "                    gr.update(),  # event_coverage_display\n",
    "                    df_update,\n",
    "                    html_update,\n",
    "                    summary_update,\n",
    "                    stop_btn_update,\n",
    "                    is_active\n",
    "                ]\n",
    "    \n",
    "    # Original analyze button (from Persona tab) just switches to Results tab\n",
    "    analyze_btn.click(\n",
    "        lambda: gr.update(selected=4),  # Switch to Results tab\n",
    "        outputs=[tabs]\n",
    "    )\n",
    "    \n",
    "    # Handler for Start Analysis button in Results tab (two-phase analysis)\n",
    "    def start_two_phase_analysis(case_text, analysis_config, persona, criteria, extraction_state):\n",
    "        \"\"\"Start the two-phase analysis.\"\"\"\n",
    "        if not extraction_state.get(\"extracted\", False):\n",
    "            return (\n",
    "                gr.update(value=\"‚ùå Please extract disease and events first.\"),\n",
    "                gr.update(),\n",
    "                gr.update(),\n",
    "                gr.update()\n",
    "            )\n",
    "        \n",
    "        return (\n",
    "            gr.update(value=\"üîÑ Starting two-phase analysis...\"),  # analysis_progress\n",
    "            gr.update(visible=True),  # stop_analysis_btn\n",
    "            gr.update(visible=True, value=\"\"),  # event_coverage_display\n",
    "            gr.update()  # other updates\n",
    "        )\n",
    "    \n",
    "    start_analysis_btn.click(\n",
    "        start_two_phase_analysis,\n",
    "        inputs=[case_input, analysis_config, persona_text, criteria_state, extraction_state],\n",
    "        outputs=[analysis_progress, stop_analysis_btn, event_coverage_display, live_results_df]\n",
    "    ).then(\n",
    "        run_full_analysis_two_phase,\n",
    "        inputs=[case_input, analysis_config, persona_text, criteria_state, extraction_state],\n",
    "        outputs=[results_state, analysis_progress, event_coverage_display, live_results_df, detailed_analysis_html, final_analysis_btn, stop_analysis_btn, analysis_active]\n",
    "    )\n",
    "    \n",
    "    # Stop button handler\n",
    "    def stop_analysis():\n",
    "        \"\"\"Stop the ongoing analysis.\"\"\"\n",
    "        return (\n",
    "            False,  # Set analysis_active to False\n",
    "            gr.update(value=\"‚èπÔ∏è Analysis stopped by user.\"),\n",
    "            gr.update(visible=False)\n",
    "        )\n",
    "    \n",
    "    stop_analysis_btn.click(\n",
    "        stop_analysis,\n",
    "        outputs=[analysis_active, analysis_progress, stop_analysis_btn]\n",
    "    )\n",
    "    \n",
    "    # Final Analysis tab handlers\n",
    "    def prepare_final_analysis_tab(results):\n",
    "        \"\"\"Prepare the final analysis tab with article selection.\"\"\"\n",
    "        if not results:\n",
    "            return (\n",
    "                gr.update(choices=[], value=[]),  # article_selections\n",
    "                gr.update(value=\"No articles available\"),  # selected_count\n",
    "                gr.update(value=\"Estimated tokens: 0\"),  # token_estimate\n",
    "                gr.update(interactive=False),  # generate_final_btn\n",
    "                [],  # selected_articles_state\n",
    "                gr.update(visible=False)  # final_analysis_btn\n",
    "            )\n",
    "        \n",
    "        # Create choices for checkbox group\n",
    "        choices = []\n",
    "        for idx, article in enumerate(results):\n",
    "            metadata = article.get('metadata', article)\n",
    "            choice_label = f\"[Score: {article.get('score', 0):.1f}] {metadata.get('title', 'Unknown')[:100]}... ({metadata.get('journal_title', 'Unknown')}, {metadata.get('year', 'N/A')})\"\n",
    "            choices.append((choice_label, idx))\n",
    "        \n",
    "        # Select top 10 by default\n",
    "        default_selected = list(range(min(10, len(results))))\n",
    "        \n",
    "        # Calculate initial token estimate\n",
    "        selected_articles = [results[i] for i in default_selected]\n",
    "        total_tokens = sum(estimate_tokens(article.get('content', '')) for article in selected_articles)\n",
    "        \n",
    "        return (\n",
    "            gr.update(choices=choices, value=default_selected),  # article_selections\n",
    "            gr.update(value=f\"{len(default_selected)} articles selected\"),  # selected_count\n",
    "            gr.update(value=f\"Estimated tokens: {total_tokens:,}\"),  # token_estimate\n",
    "            gr.update(interactive=len(default_selected) > 0),  # generate_final_btn\n",
    "            selected_articles,  # selected_articles_state\n",
    "            gr.update(visible=True)  # final_analysis_btn\n",
    "        )\n",
    "    \n",
    "    def update_article_selection(selected_indices, all_results):\n",
    "        \"\"\"Update selection count and token estimate.\"\"\"\n",
    "        if not all_results or selected_indices is None:\n",
    "            return (\n",
    "                gr.update(value=\"0 articles selected\"),\n",
    "                gr.update(value=\"Estimated tokens: 0\"),\n",
    "                gr.update(interactive=False),\n",
    "                []\n",
    "            )\n",
    "        \n",
    "        selected_articles = [all_results[i] for i in selected_indices]\n",
    "        total_tokens = sum(estimate_tokens(article.get('content', '')) for article in selected_articles)\n",
    "        \n",
    "        return (\n",
    "            gr.update(value=f\"{len(selected_indices)} articles selected\"),\n",
    "            gr.update(value=f\"Estimated tokens: {total_tokens:,}\"),\n",
    "            gr.update(interactive=len(selected_indices) > 0),\n",
    "            selected_articles\n",
    "        )\n",
    "    \n",
    "    def select_all_articles(all_results):\n",
    "        \"\"\"Select all articles.\"\"\"\n",
    "        if not all_results:\n",
    "            return gr.update()\n",
    "        return gr.update(value=list(range(len(all_results))))\n",
    "    \n",
    "    def deselect_all_articles():\n",
    "        \"\"\"Deselect all articles.\"\"\"\n",
    "        return gr.update(value=[])\n",
    "    \n",
    "    def generate_final_analysis(case_text, extraction_state, selected_articles):\n",
    "        \"\"\"Generate the final analysis with streaming.\"\"\"\n",
    "        if not selected_articles:\n",
    "            yield gr.update(value=\"‚ùå Please select at least one article.\")\n",
    "            return\n",
    "        \n",
    "        # Extract disease and events\n",
    "        disease = extraction_state.get('disease', '')\n",
    "        events = extraction_state.get('events_list', [])\n",
    "        \n",
    "        # Stream the analysis\n",
    "        yield gr.update(value=\"üîÑ Generating comprehensive analysis...\")\n",
    "        \n",
    "        accumulated_text = \"\"\n",
    "        for chunk in generate_final_analysis_stream(case_text, disease, events, selected_articles, genai_client):\n",
    "            accumulated_text = chunk\n",
    "            yield gr.update(value=accumulated_text)\n",
    "    \n",
    "    # Connect final analysis button to switch tabs and prepare selection\n",
    "    final_analysis_btn.click(\n",
    "        lambda results: prepare_final_analysis_tab(results),\n",
    "        inputs=[results_state],\n",
    "        outputs=[article_selections, selected_count, token_estimate, generate_final_btn, selected_articles_state, final_analysis_btn]\n",
    "    ).then(\n",
    "        lambda: gr.update(selected=5),\n",
    "        outputs=[tabs]\n",
    "    )\n",
    "    \n",
    "    # Update selection handlers\n",
    "    article_selections.change(\n",
    "        update_article_selection,\n",
    "        inputs=[article_selections, results_state],\n",
    "        outputs=[selected_count, token_estimate, generate_final_btn, selected_articles_state]\n",
    "    )\n",
    "    \n",
    "    select_all_btn.click(\n",
    "        select_all_articles,\n",
    "        inputs=[results_state],\n",
    "        outputs=[article_selections]\n",
    "    )\n",
    "    \n",
    "    deselect_all_btn.click(\n",
    "        deselect_all_articles,\n",
    "        outputs=[article_selections]\n",
    "    )\n",
    "    \n",
    "    # Prompt editing handlers\n",
    "    def reset_analysis_prompt():\n",
    "        \"\"\"Reset the analysis prompt to default.\"\"\"\n",
    "        return gr.update(value=FINAL_ANALYSIS_PROMPT_TEMPLATE)\n",
    "    \n",
    "    def load_example_analysis_prompt(example_prompts):\n",
    "        \"\"\"Load a random example prompt.\"\"\"\n",
    "        import random\n",
    "        prompt_name = random.choice(list(example_prompts.keys()))\n",
    "        return gr.update(value=example_prompts[prompt_name])\n",
    "    \n",
    "    reset_prompt_btn.click(\n",
    "        reset_analysis_prompt,\n",
    "        outputs=[analysis_prompt_input]\n",
    "    )\n",
    "    \n",
    "    load_example_prompt_btn.click(\n",
    "        load_example_analysis_prompt,\n",
    "        inputs=[example_prompts],\n",
    "        outputs=[analysis_prompt_input]\n",
    "    )\n",
    "    \n",
    "    # Modified generate_final_analysis to use custom prompt\n",
    "    def generate_final_analysis_with_custom_prompt(case_text, extraction_state, selected_articles, custom_prompt):\n",
    "        \"\"\"Generate the final analysis with custom prompt and streaming.\"\"\"\n",
    "        if not selected_articles:\n",
    "            yield gr.update(value=\"‚ùå Please select at least one article.\")\n",
    "            return\n",
    "        \n",
    "        # Extract disease and events\n",
    "        disease = extraction_state.get('disease', '')\n",
    "        events = extraction_state.get('events_list', [])\n",
    "        \n",
    "        # Create custom prompt by filling in the template\n",
    "        sorted_articles = sorted(selected_articles, key=lambda x: x.get('score', 0), reverse=True)\n",
    "        \n",
    "        # Format all selected articles\n",
    "        articles_content_parts = []\n",
    "        for idx, article in enumerate(sorted_articles, 1):\n",
    "            articles_content_parts.append(format_article_for_analysis(article, idx))\n",
    "        \n",
    "        # Join all articles with separator\n",
    "        articles_content = (\"\\n\" + \"=\"*80 + \"\\n\").join(articles_content_parts)\n",
    "        \n",
    "        # Fill in the custom template\n",
    "        try:\n",
    "            filled_prompt = custom_prompt.format(\n",
    "                case_description=case_text,\n",
    "                primary_focus=disease,\n",
    "                key_concepts=', '.join(events),\n",
    "                articles_content=articles_content\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            yield gr.update(value=f\"‚ùå Error in prompt template: Missing placeholder {{{e}}}. Please check your prompt template.\")\n",
    "            return\n",
    "        \n",
    "        # Stream the analysis\n",
    "        yield gr.update(value=\"üîÑ Generating comprehensive analysis...\")\n",
    "        \n",
    "        # Use the existing streaming logic but with custom prompt\n",
    "        if not genai_client:\n",
    "            yield gr.update(value=\"‚ùå Gemini client not initialized. Please complete setup first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Generate content with streaming\n",
    "            config = GenerateContentConfig(\n",
    "                temperature=0.3,\n",
    "                max_output_tokens=8192,\n",
    "                candidate_count=1,\n",
    "                thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET)\n",
    "            )\n",
    "            \n",
    "            # Stream the response\n",
    "            try:\n",
    "                response_stream = genai_client.models.generate_content_stream(\n",
    "                    model=MODEL_ID,\n",
    "                    contents=[filled_prompt],\n",
    "                    config=config\n",
    "                )\n",
    "                \n",
    "                accumulated_text = \"\"\n",
    "                \n",
    "                for chunk in response_stream:\n",
    "                    if hasattr(chunk, 'candidates') and chunk.candidates:\n",
    "                        for candidate in chunk.candidates:\n",
    "                            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):\n",
    "                                for part in candidate.content.parts:\n",
    "                                    if hasattr(part, 'text'):\n",
    "                                        accumulated_text += part.text\n",
    "                                        # Yield the accumulated content so far\n",
    "                                        yield gr.update(value=accumulated_text)\n",
    "                \n",
    "                # If no content was generated\n",
    "                if not accumulated_text:\n",
    "                    yield gr.update(value=\"‚ùå No analysis was generated. Please try again.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                yield gr.update(value=f\"‚ùå Error during analysis generation: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            yield gr.update(value=f\"‚ùå Error generating final analysis: {str(e)}\")\n",
    "    \n",
    "    # Generate final analysis with custom prompt\n",
    "    generate_final_btn.click(\n",
    "        generate_final_analysis_with_custom_prompt,\n",
    "        inputs=[case_input, extraction_state, selected_articles_state, analysis_prompt_input],\n",
    "        outputs=[final_analysis_display]\n",
    "    )\n",
    "\n",
    "    # Initial load\n",
    "    demo.load(get_initial_projects, outputs=[project_dropdown, status_output])\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
